{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f9b686-4dee-4846-b006-9d3b39292662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.scaler import STMatrixStandardScaler\n",
    "from utils.helper import format_stmatrix, train_test_split, fix_seed\n",
    "from dataset import STDataset\n",
    "from trainer import Trainer\n",
    "from logger import Logger\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a66af52-fa9b-44a1-8e3d-7c1ab733e773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f0112-9df1-4430-a141-c4b94a5a4962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 前処理してデータセットを作成\n",
    "- 渋滞量 -> フラグに変換\n",
    "- 方向 -> 0/1に変換\n",
    "    - 上り: 0, 下り: 1\n",
    "- 四半期を数値化\n",
    "- 使用しないカラムを落とす\n",
    "    - 天気 + `index`, `data`, `road_code`, `jam_type`\n",
    "- 速度の欠損を埋める\n",
    "- OCC -> [0, 1]に変換\n",
    "- 型変換\n",
    "    - float64 -> float32\n",
    "    - 区間の名前, コード, 県コード, 0/1系, カレンダーデータをcategoryデータに\n",
    "    - degreeをint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b47c5-ece1-4061-b622-f0c26c9de6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 道路名\n",
    "# TARGET_ROAD='tateyama'\n",
    "TARGET_ROAD='kannetsu'\n",
    "\n",
    "# 交通量\n",
    "PROCESSED_DATA_DIR = '../Input_processed_data'\n",
    "TRAFFIC_DIR = f'{PROCESSED_DATA_DIR}/traffic'\n",
    "TRAFFIC_CSV = f'{TRAFFIC_DIR}/{TARGET_ROAD}_20220621all-merged_filled_15min.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58e808-e64e-4d7d-836d-04fd532a1054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_types = {'start_code': str, 'end_code': str, 'road_code': str, 'jam_type': str,}\n",
    "\n",
    "df = pd.read_csv(TRAFFIC_CSV, parse_dates=True, index_col='datetime', dtype=col_types).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898041e-0cc7-420f-9363-73a3edc61e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate(df, col):\n",
    "    '''\n",
    "    dfのcolカラム内の欠損を区間ごとに線形補間する\n",
    "    '''\n",
    "    f = lambda g: g.interpolate(method='linear', axis=0)\n",
    "    \n",
    "    df.sort_values('datetime', inplace=True)\n",
    "    df[col] = df.groupby(['start_code', 'end_code'])[col].apply(f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    # 「年」情報を入れる\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    # 渋滞フラグ 0/1\n",
    "    df['jam_quantity'] = np.where(df['speed'] < 40, 1, 0)\n",
    "    # 方向を数値化\n",
    "    direction_map = {'上り': 0, '下り': 1}\n",
    "    df['direction'] = df['direction'].map(direction_map)\n",
    "    # 四半期を数値化\n",
    "    df['quarter'] = df['quarter'].str[-1]\n",
    "    \n",
    "    # object型のカラム, いらないカラムを落とす\n",
    "    drop_cols = [\n",
    "        'index', 'date', 'road_code', 'pressure', 'rainfall', \n",
    "        'temperature', 'humidity', 'wind_speed', 'daylight_hours', \n",
    "        'snowfall', 'deepest_snowfall', 'weather_description', 'jam_type'\n",
    "    ]\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # 速度の欠損を埋める\n",
    "    df = linear_interpolate(df, 'speed')\n",
    "    # OCCを[0,1]に変換\n",
    "    df['OCC'] = df['OCC'] / 100.0\n",
    "    \n",
    "    # 型変換\n",
    "    f64_cols = df.select_dtypes(include=[np.float64]).columns\n",
    "    df.loc[:, f64_cols] = df.loc[:, f64_cols].astype(np.float32)\n",
    "    i64_cols = df.select_dtypes(include=[int]).columns\n",
    "    df.loc[:, i64_cols] = df.loc[:, i64_cols].astype(np.int32)\n",
    "    \n",
    "    type_map = {\n",
    "        'start_name': 'category',\n",
    "        'end_name': 'category',\n",
    "        'start_code': 'category',\n",
    "        'end_code': 'category',\n",
    "        'start_pref_code': 'category',\n",
    "        'end_pref_code': 'category',\n",
    "        'direction': 'category',\n",
    "        'month': 'category',\n",
    "        'day': 'category',\n",
    "        'dayofweek': 'category',\n",
    "        'is_holiday': 'category',\n",
    "        'hour': 'category',\n",
    "        'quarter': 'category',\n",
    "        'jam_quantity': 'category',\n",
    "        'start_degree': np.int32,\n",
    "        'end_degree': np.int32,\n",
    "        'degree_sum': np.int32,\n",
    "    }\n",
    "    df = df.astype(type_map)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d5e8e-66a4-4c63-a76c-984f49cdec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, start_date, end_date, pkl_name):\n",
    "    tmp = df.loc[(df['datetime'] >= pd.Timestamp(start_date)) & (df['datetime'] < pd.Timestamp(end_date))]\n",
    "    # tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp = preprocess(tmp.copy())\n",
    "    tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp.to_pickle(pkl_name)\n",
    "\n",
    "# whole dataset\n",
    "start_date = '2021/4/2'\n",
    "end_date = '2022/6/1'\n",
    "pkl_name = './datasets/kannetsu_210402-220531.pkl'\n",
    "\n",
    "create_dataset(df, start_date, end_date, pkl_name)\n",
    "\n",
    "# mini dataset\n",
    "start_date = '2021/4/2'\n",
    "end_date = '2021/6/1'\n",
    "pkl_name = './datasets/kannetsu_210402-210531.pkl'\n",
    "\n",
    "create_dataset(df, start_date, end_date, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7f12-2979-4952-8165-d5c01122d1f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## データセットを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2840688e-38f3-4355-bd7e-e1655e966cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini\n",
    "df_test = pd.read_pickle('./datasets/kannetsu_210402-210531.pkl')\n",
    "# whole\n",
    "df_all = pd.read_pickle('./datasets/kannetsu_210402-220531.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46a5f703-fc2c-4d76-9bb8-61bc9e565947",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_table = pd.read_pickle('./datasets/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle('./datasets/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9502253-a633-48b8-bc79-f90b5cf43d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>start_name</th>\n",
       "      <th>end_name</th>\n",
       "      <th>start_code</th>\n",
       "      <th>end_code</th>\n",
       "      <th>start_pref_code</th>\n",
       "      <th>end_pref_code</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>search_unspec_10d</th>\n",
       "      <th>minute_quarter</th>\n",
       "      <th>allCars</th>\n",
       "      <th>jam_quantity</th>\n",
       "      <th>search_15min</th>\n",
       "      <th>OCC</th>\n",
       "      <th>speed</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>所沢</td>\n",
       "      <td>大泉ＪＣＴ</td>\n",
       "      <td>1800006</td>\n",
       "      <td>1110210</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>35.806149</td>\n",
       "      <td>35.755821</td>\n",
       "      <td>139.535507</td>\n",
       "      <td>...</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>86.421524</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>越後川口</td>\n",
       "      <td>堀之内</td>\n",
       "      <td>1800171</td>\n",
       "      <td>1800161</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.264629</td>\n",
       "      <td>37.251381</td>\n",
       "      <td>138.839630</td>\n",
       "      <td>...</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.411766</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>堀之内</td>\n",
       "      <td>小出</td>\n",
       "      <td>1800161</td>\n",
       "      <td>1800156</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.251381</td>\n",
       "      <td>37.213329</td>\n",
       "      <td>138.928635</td>\n",
       "      <td>...</td>\n",
       "      <td>786.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.285713</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime start_name end_name start_code end_code start_pref_code  \\\n",
       "0 2021-04-02         所沢    大泉ＪＣＴ    1800006  1110210              11   \n",
       "1 2021-04-02       越後川口      堀之内    1800171  1800161              15   \n",
       "2 2021-04-02        堀之内       小出    1800161  1800156              15   \n",
       "\n",
       "  end_pref_code  start_lat    end_lat   start_lng  ...  search_unspec_10d  \\\n",
       "0            13  35.806149  35.755821  139.535507  ...             2156.0   \n",
       "1            15  37.264629  37.251381  138.839630  ...              798.0   \n",
       "2            15  37.251381  37.213329  138.928635  ...              786.0   \n",
       "\n",
       "   minute_quarter  allCars jam_quantity search_15min   OCC      speed  year  \\\n",
       "0               0    223.0            0          8.0  0.03  86.421524  2021   \n",
       "1               0     17.0            0          0.0  0.00  89.411766  2021   \n",
       "2               0     14.0            0          1.0  0.00  90.285713  2021   \n",
       "\n",
       "  datetime_id  section_id  \n",
       "0           8          31  \n",
       "1           8           2  \n",
       "2           8           3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e4d66-8ae9-4d1a-a770-d55c4c82dfce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 時間, 区間にembedding用のIDを割り振る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91cfa6-79bd-4901-b38d-7e436704000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間情報を管理するためのテーブルを作成 (month x hour x dayofweeks x is_holidays)\n",
    "# months = range(1, 12+1)\n",
    "# hours = range(24)\n",
    "# dayofweeks = range(1, 7+1)\n",
    "# is_holidays = (0, 1)\n",
    "\n",
    "# dt_table = pd.DataFrame(itertools.product(months, hours, dayofweeks, is_holidays), columns=['month', 'hour', 'dayofweek', 'is_holiday'], dtype='category')\n",
    "# dt_table = dt_table.query('dayofweek not in (6, 7) | is_holiday != 0').reset_index(drop=True)\n",
    "# dt_table = dt_table.reset_index().set_index(['month', 'hour', 'dayofweek', 'is_holiday']).astype('category')\n",
    "\n",
    "# dt_table.to_pickle('./datasets/datetime_table.pkl')\n",
    "\n",
    "# dt_table = pd.read_pickle('./datasets/datetime_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48291632-a12e-4e3c-a8f5-9ba4e8f91aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間情報を管理するためのテーブルを作成 (hour x dayofweeks x is_holidays)\n",
    "# hours = range(24)\n",
    "# dayofweeks = range(1, 7+1)\n",
    "# is_holidays = (0, 1)\n",
    "\n",
    "# dt_table = pd.DataFrame(itertools.product(hours, dayofweeks, is_holidays), columns=['hour', 'dayofweek', 'is_holiday'], dtype='category')\n",
    "# dt_table = dt_table.query('dayofweek not in (6, 7) | is_holiday != 0').reset_index(drop=True)\n",
    "# dt_table = dt_table.reset_index().set_index(['hour', 'dayofweek', 'is_holiday']).astype('category')\n",
    "\n",
    "# dt_table.to_pickle('./datasets/mini_datetime_table.pkl')\n",
    "\n",
    "# dt_table = pd.read_pickle('./datasets/mini_datetime_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b54d50-3eba-4d3e-93ea-768d54c39097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区間情報を管理するためのテーブルを作成\n",
    "# sec_table = df_test[['start_name', 'end_name', 'direction', 'KP']].drop_duplicates()\n",
    "# 区間順にソート\n",
    "# sort_f = lambda g: g.sort_values('KP', ascending=(g.name == 1))\n",
    "# sec_table = sec_table.groupby('direction').apply(sort_f).reset_index(drop=True)\n",
    "\n",
    "# sec_table.to_pickle('./datasets/section_table.pkl')\n",
    "# sec_table.head(3)\n",
    "\n",
    "# sec_table = pd.read_pickle('./datasets/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7ac6bbd-5e5d-4daa-b997-400b4b7672f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2id(df, dt_table):\n",
    "    time_col = ['hour', 'dayofweek', 'is_holiday']\n",
    "    f = lambda g: g.assign(datetime_id=dt_table.loc[g.name, 'index'])\n",
    "    df = df.groupby(time_col).apply(f)\n",
    "    df['datetime_id'] = df['datetime_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def section2id(df, sec_table):\n",
    "    f = lambda g: g.assign(section_id=sec_table.query(f'start_name == \"{g.name[0]}\" & end_name == \"{g.name[1]}\"').index.item())\n",
    "    df = df.groupby(['start_name', 'end_name']).apply(f)\n",
    "    df['section_id'] = df['section_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def identify(df, dt_table, sec_table):\n",
    "    df = datetime2id(df, dt_table)\n",
    "    df = section2id(df, sec_table)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8ae9e67-47b0-4274-b963-edf85e4b3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = identify(df_test, dt_table, sec_table)\n",
    "df_test.to_pickle('./datasets/kannetsu_210402-210531.pkl')\n",
    "\n",
    "df_all = identify(df_all, dt_table, sec_table)\n",
    "df_all.to_pickle('./datasets/kannetsu_210402-220531.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a0e9b-14b1-434c-8de6-2aa603db4727",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Spatial Temporal Matrixに整形\n",
    "- 区間数 x 時系列数 の行列\n",
    "- 実際は 区間数 x 時系列数 x 特徴量数 のテンソル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "388e22b3-fa73-4af8-83ae-dad170795ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tr = pd.read_pickle('./datasets/kannetsu_210402-210519.pkl')\n",
    "df_test_va = pd.read_pickle('./datasets/kannetsu_210520-210531.pkl')\n",
    "\n",
    "df_all_tr = pd.read_pickle('./datasets/kannetsu_210402-220228.pkl')\n",
    "df_all_va = pd.read_pickle('./datasets/kannetsu_210402-210519.pkl')\n",
    "\n",
    "dt_table = pd.read_pickle('./datasets/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle('./datasets/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b39c58f-57dc-48c9-a557-0f5e71ead960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 特徴量の元になる列\n",
    "# time_col = ['month', 'hour', 'dayofweek', 'is_holiday']\n",
    "# section_col = ['direction', 'lane_count', 'KP']\n",
    "time_col = ['datetime_id']\n",
    "section_col = ['section_id']\n",
    "search_col = ['search_15min', 'search_unspec_1d']\n",
    "traffic_col = ['allCars']\n",
    "\n",
    "feature_col = time_col + section_col + search_col + traffic_col\n",
    "# feature_col = time_col + section_col + traffic_col\n",
    "# feature_col = search_col + traffic_col\n",
    "\n",
    "# 予測対象\n",
    "target_col = 'allCars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "36cfca28-8fa1-49f8-a821-5b7c5f49d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 31968, 63]) torch.Size([5, 4608, 63]) torch.Size([1, 31968, 63]) torch.Size([1, 4608, 63])\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr = format_stmatrix(df_all_tr, sec_table, feature_col, target_col)\n",
    "X_va, y_va = format_stmatrix(df_all_va, sec_table, feature_col, target_col)\n",
    "print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffac485-c759-4a8c-be33-a714e2b4ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(X_tr, './datasets/features_train.pkl')\n",
    "# torch.save(X_va, './datasets/features_test.pkl')\n",
    "# torch.save(y_tr, './datasets/labels_train.pkl')\n",
    "# torch.save(y_va, './datasets/labels_test.pkl')\n",
    "\n",
    "# torch.save(X_tr, './datasets/mini_features_train.pkl')\n",
    "# torch.save(X_va, './datasets/mini_features_test.pkl')\n",
    "# torch.save(y_tr, './datasets/mini_labels_train.pkl')\n",
    "# torch.save(y_va, './datasets/mini_labels_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376cb0a-2709-4e34-94af-8c23af4a418f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 標準化・正規化\n",
    "- 標準化を行う\n",
    "- 時間特徴量（`month`, `hour`, `day_of_week`）はsin, cosで変換するのもやってみる\n",
    "- 検索数, 台数は上り・下り別でもやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70b43f0a-daa0-4011-8eb4-a3d1c155acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4608, 63]) torch.Size([5, 1152, 63])\n",
      "torch.Size([1, 4608, 63]) torch.Size([1, 1152, 63])\n"
     ]
    }
   ],
   "source": [
    "dt_table = pd.read_pickle('./datasets/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle('./datasets/section_table.pkl')\n",
    "\n",
    "# X_tr = torch.load('./datasets/features_train.pkl')\n",
    "# X_va = torch.load('./datasets/features_test.pkl')\n",
    "# y_tr = torch.load('./datasets/labels_train.pkl')\n",
    "# y_va = torch.load('./datasets/labels_test.pkl')\n",
    "\n",
    "X_tr = torch.load('./datasets/mini_features_train.pkl')\n",
    "X_va = torch.load('./datasets/mini_features_test.pkl')\n",
    "y_tr = torch.load('./datasets/mini_labels_train.pkl')\n",
    "y_va = torch.load('./datasets/mini_labels_test.pkl')\n",
    "\n",
    "print(X_tr.shape, X_va.shape)\n",
    "print(y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d59f0469-e844-48d9-b897-4c4b2596f2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ID列は飛ばして標準化\n",
    "skip_features = [0, 1]\n",
    "scaler = STMatrixStandardScaler(skip_features=skip_features)\n",
    "\n",
    "scaler.fit(X_tr)\n",
    "X_tr_norm = scaler.transform(X_tr)\n",
    "\n",
    "scaler.fit(X_va)\n",
    "X_va_norm = scaler.transform(X_va)\n",
    "\n",
    "torch.save(X_tr_norm, './datasets/mini_features_train_norm.pkl')\n",
    "torch.save(X_va_norm, './datasets/mini_features_test_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "257b33a6-33cb-44fc-a345-50fb13db5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratio = 0.2\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_norm, y, test_ratio)\n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b4d27-83ee-4e74-8cbd-e2f88b5bc7e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データセットの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265d39fd-7d3b-47e2-96d6-aad31ba1ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 1) (63, 4)\n",
      "torch.Size([5, 31968, 63]) torch.Size([5, 8832, 63])\n",
      "torch.Size([1, 31968, 63]) torch.Size([1, 8832, 63])\n"
     ]
    }
   ],
   "source": [
    "dt_table = pd.read_pickle(f'{config.TABLES_DIR}/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle(f'{config.TABLES_DIR}/section_table.pkl')\n",
    "\n",
    "X_tr = torch.load(f'{config.DATASET_DIR}/features_train_norm.pkl')\n",
    "X_va = torch.load(f'{config.DATASET_DIR}/features_test_norm.pkl')\n",
    "y_tr = torch.load(f'{config.DATASET_DIR}/labels_train.pkl')\n",
    "y_va = torch.load(f'{config.DATASET_DIR}/labels_test.pkl')\n",
    "\n",
    "# X_tr = torch.load(f'{config.MINI_DIR}/mini_features_train_norm.pkl')\n",
    "# X_va = torch.load(f'{config.MINI_DIR}/mini_features_test_norm.pkl')\n",
    "# y_tr = torch.load(f'{config.MINI_DIR}/mini_labels_train.pkl')\n",
    "# y_va = torch.load(f'{config.MINI_DIR}/mini_labels_test.pkl')\n",
    "\n",
    "print(dt_table.shape, sec_table.shape)\n",
    "print(X_tr.shape, X_va.shape)\n",
    "print(y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6731a3ac-b9fc-46dd-87d4-050fa49aee96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_step = 96\n",
    "prediction_horizon = 1\n",
    "space_window = None\n",
    "static_col = None\n",
    "\n",
    "dataset_train = STDataset(X_tr, y_tr, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)\n",
    "\n",
    "dataset_valid = STDataset(X_va, y_va, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340b55f-dcc6-4f86-a1d9-ed3c02faaaf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Networkの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68688362-29fa-473b-8071-f742d901baf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a17bfe-5110-4967-9810-f2b11c7bddfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_layers, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hid_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(x)\n",
    "        out = self.fc(h[0])\n",
    "        return out\n",
    "    \n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hid_dim, num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(1, hid_dim, num_layers, batch_first=batch_first)\n",
    "        self.search_lstm = nn.LSTM(2, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(x[..., -1:])\n",
    "        s_outs, (s_h, s_c) = self.search_lstm(x[..., -3:-1])\n",
    "        out = torch.cat([h[0], s_h[0]], dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41aa92-6edb-4ee7-940c-990101e90046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab3e372-219a-45e6-807f-802404cf8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config.BATCH_SIZE\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e034a2e-a655-4452-8193-95b577337d1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c322e5d-ec12-4ce1-be2c-c78628467dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 50\n",
    "hid_dim = 64\n",
    "\n",
    "# path\n",
    "model_name = 'LSTM'\n",
    "log_path = f'./logs/{model_name}.log'\n",
    "# log_path = None\n",
    "\n",
    "model = LSTM(hid_dim).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed214934-0aab-4ae0-8701-4f692c8f670f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 11:30:01.293993 | Epoch: 1 | Train Loss: 86.123, Train Time: 53.68 [sec] | Valid Loss: 31.519, Valid Time: 6.51 [sec]\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b1086e4-af21-4f62-9f76-a8dce73694e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:00:25.199092 | Epoch: 65 | Train Loss: 15.600, Train Time: 52.03 [sec] | Valid Loss: 17.158, Valid Time: 3.43 [sec]\n",
      "2022-08-13 16:05:01.422273 | Epoch: 70 | Train Loss: 15.582, Train Time: 51.30 [sec] | Valid Loss: 17.382, Valid Time: 3.42 [sec]\n"
     ]
    }
   ],
   "source": [
    "extra_epochs = 10\n",
    "\n",
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, extra_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bfb0df9-effc-4d3d-8582-0ff50cf01601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./models/LSTM_{trainer.current_epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95806d53-47b4-4009-b34f-c4706e0fb947",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 学習曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb674a8-cb27-4040-ae77-1b140045fe1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(range(len(trainer.train_losses)), trainer.train_losses)\n",
    "ax.plot(range(len(trainer.val_losses)), trainer.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313512b5-4c4d-48aa-ba0f-63c3d3e74035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.validate(train_loader))\n",
    "print(trainer.validate(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849861c-36f1-4999-8a66-566bac30fc34",
   "metadata": {},
   "source": [
    "## 予測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb058e7-c2b5-4f58-97c9-cd0639102317",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2022/5/1') - dt.timedelta(minutes=15) * time_step\n",
    "end_date = pd.Timestamp('2022/5/9') - dt.timedelta(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa995b0-32cd-4ee1-b6af-fe3de2fd3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sec_table.shape[0]\n",
    "T = int((end_date - start_date).total_seconds() // (60 * 15))\n",
    "D = len(feature_col)\n",
    "\n",
    "X_test = torch.empty((S, T, D), dtype=torch.float32)\n",
    "y_test = torch.empty((S, T, 1), dtype=torch.float32)\n",
    "\n",
    "for sec_id, (s_name, e_name, *_) in sec_table.iterrows():\n",
    "    query = f'start_name == \"{s_name}\" & end_name == \"{e_name}\"'\n",
    "    df_sec = df_all.query(f'start_name == \"{s_name}\" & end_name == \"{e_name}\"')\n",
    "    df_sec = df_sec[(df_sec['datetime'] >= start_date) & (df_sec['datetime'] < end_date)]\n",
    "    \n",
    "    data = df_sec.loc[:, feature_col].values\n",
    "    target = df_sec.loc[:, target_col].values\n",
    "    \n",
    "    X_test[sec_id] = torch.from_numpy(data)\n",
    "    y_test[sec_id, :, 0] = torch.from_numpy(target)\n",
    "    \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "dataset_test = STDataset(X_test, y_test, time_step=time_step, prediction_horizon=prediction_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea87be-7c0d-4929-9726-a313eceb9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_test[:][0].to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(data)\n",
    "\n",
    "pred = pred.view(S, -1).to(device='cpu')\n",
    "target = dataset_test[:][1].view(S, -1).to(device='cpu')\n",
    "\n",
    "plot_sections = [27, 36]\n",
    "fig, axes = plt.subplots(len(plot_sections), 1, figsize=(15, 7))\n",
    "for i, sec_id in enumerate(plot_sections):\n",
    "    axes[i].plot(target[sec_id], label='true')    \n",
    "    axes[i].plot(pred[sec_id], label='pred')\n",
    "    \n",
    "    title = f'{sec_table.loc[sec_id, \"start_name\"]} ~ {sec_table.loc[sec_id, \"end_name\"]}'\n",
    "    axes[i].set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe87e3f-1a43-4d7e-baf0-c1d0827e346d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5a7dd-2786-4b7f-8db8-1b8fd9747d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70220b82-63db-44ff-94e5-670621ccdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = df_test[(df_test['start_name'] == '鶴ヶ島') & (df_test['direction'] == 1)]\n",
    "tmp_train = tmp_train.loc[:, key_col + features]\n",
    "\n",
    "# 時系列長\n",
    "N_period = tmp_train.drop_duplicates(\"datetime\").shape[0]\n",
    "# 区間数\n",
    "N_sec = tmp_train.drop_duplicates([\"start_name\", \"end_name\"]).shape[0]\n",
    "# 特徴量数\n",
    "D = len(features)\n",
    "\n",
    "tmp_train_value = tmp_train[features].values.reshape(1, N_period, D)\n",
    "tmp_train_norm = (tmp_train_value - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c00c2-90d7-4da0-963f-7f631e0a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X = []\n",
    "\n",
    "for i in range(N_sec):\n",
    "    for t in range(time_step, N_period - 24):\n",
    "        time_pred = t + 24\n",
    "        time_input = (t - time_step, t + time_step + 1)\n",
    "        x_ = tmp_train_norm[i, time_input[0] : time_input[1]]\n",
    "        tmp_X.append(x_)\n",
    "\n",
    "tmp_X = torch.from_numpy(np.array(tmp_X, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1369b62-c2ce-4512-a50c-e050ade2ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model(tmp_X.to(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a600e-c0c8-4e35-ab44-0070998eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.arange(time_step, N_period - 24) + 24\n",
    "tmp_y = tmp_train.iloc[ys, -1].values.reshape(-1, 1)\n",
    "tmp_y = torch.from_numpy(tmp_y).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7908b-8ca8-45f2-ab77-9f9571a38319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7632f-df57-4347-a9e6-bf336e0cfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122439-cf23-4510-9a91-ab1dfab22159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for data, target in dataset_train:\n",
    "        if i >= 10:\n",
    "            break\n",
    "        i += 1\n",
    "        print(f'------- {i} -------')\n",
    "        out = model(data.to(device=device))\n",
    "        print(target)\n",
    "        print(out)\n",
    "        print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cdb92-cd84-4abb-97f8-65ea5a5f3cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 3000\n",
    "in_dim = X_train.shape[-1]\n",
    "hid_dim = 100\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device=device)\n",
    "        target = target.unsqueeze(1).to(device=device)\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch < 3 or (epoch + 1) % 100 == 0:\n",
    "        print(f'{dt.datetime.now()} | Epoch {epoch+1} | Loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
