{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f9b686-4dee-4846-b006-9d3b39292662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a66af52-fa9b-44a1-8e3d-7c1ab733e773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529b47c5-ece1-4061-b622-f0c26c9de6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 道路名\n",
    "# TARGET_ROAD='tateyama'\n",
    "TARGET_ROAD='kannetsu'\n",
    "\n",
    "# 交通量\n",
    "PROCESSED_DATA_DIR = '../Input_processed_data'\n",
    "TRAFFIC_DIR = f'{PROCESSED_DATA_DIR}/traffic'\n",
    "TRAFFIC_CSV = f'{TRAFFIC_DIR}/{TARGET_ROAD}_20220621all-merged_filled_1h.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b58e808-e64e-4d7d-836d-04fd532a1054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'start_code': str,\n",
    "    'end_code': str,\n",
    "    'road_code': str,\n",
    "    'jam_type': str,\n",
    "}\n",
    "\n",
    "df = pd.read_csv(TRAFFIC_CSV, parse_dates=True, index_col='datetime', dtype=col_types).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c81481f0-5c87-4aff-926f-7285d607613f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date='2021/5/1'\n",
    "end_date='2022/5/1'\n",
    "\n",
    "df_test = df.loc[(df['datetime'] >= pd.Timestamp(start_date)) & (df['datetime'] < pd.Timestamp(end_date))]\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ef1cca7e-4c73-44bd-a62f-0f345247053a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 551880 entries, 0 to 551879\n",
      "Data columns (total 51 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   datetime             551880 non-null  datetime64[ns]\n",
      " 1   index                551880 non-null  int64         \n",
      " 2   start_name           551880 non-null  object        \n",
      " 3   end_name             551880 non-null  object        \n",
      " 4   start_code           551880 non-null  object        \n",
      " 5   end_code             551880 non-null  object        \n",
      " 6   start_pref_code      551880 non-null  int64         \n",
      " 7   end_pref_code        551880 non-null  int64         \n",
      " 8   start_lat            551880 non-null  float64       \n",
      " 9   end_lat              551880 non-null  float64       \n",
      " 10  start_lng            551880 non-null  float64       \n",
      " 11  end_lng              551880 non-null  float64       \n",
      " 12  start_degree         551880 non-null  float64       \n",
      " 13  end_degree           551880 non-null  float64       \n",
      " 14  quarter              551880 non-null  object        \n",
      " 15  month                551880 non-null  int64         \n",
      " 16  day                  551880 non-null  int64         \n",
      " 17  dayofweek            551880 non-null  int64         \n",
      " 18  is_holiday           551880 non-null  int64         \n",
      " 19  hour                 551880 non-null  int64         \n",
      " 20  lane_count           551880 non-null  int64         \n",
      " 21  KP                   551880 non-null  float64       \n",
      " 22  direction            551880 non-null  object        \n",
      " 23  start_KP             551880 non-null  float64       \n",
      " 24  end_KP               551880 non-null  float64       \n",
      " 25  road_distance        551880 non-null  float64       \n",
      " 26  date                 551880 non-null  object        \n",
      " 27  pressure             551880 non-null  float64       \n",
      " 28  rainfall             551880 non-null  float64       \n",
      " 29  temperature          551880 non-null  float64       \n",
      " 30  humidity             551880 non-null  float64       \n",
      " 31  wind_speed           551880 non-null  float64       \n",
      " 32  daylight_hours       551880 non-null  float64       \n",
      " 33  snowfall             551880 non-null  float64       \n",
      " 34  deepest_snowfall     551880 non-null  float64       \n",
      " 35  weather_description  551880 non-null  object        \n",
      " 36  degree_sum           551880 non-null  float64       \n",
      " 37  limit_speed          551880 non-null  int64         \n",
      " 38  distance             551880 non-null  float64       \n",
      " 39  search_5min          551880 non-null  float64       \n",
      " 40  search_1h            551880 non-null  float64       \n",
      " 41  search_unspec_1d     551880 non-null  float64       \n",
      " 42  search_unspec_3d     551880 non-null  float64       \n",
      " 43  search_unspec_7d     551880 non-null  float64       \n",
      " 44  search_unspec_10d    551880 non-null  float64       \n",
      " 45  jam_type             2947 non-null    object        \n",
      " 46  road_code            551880 non-null  object        \n",
      " 47  allCars              551880 non-null  float64       \n",
      " 48  jam_quantity         551880 non-null  int64         \n",
      " 49  OCC                  551880 non-null  float64       \n",
      " 50  speed                550878 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(29), int64(11), object(10)\n",
      "memory usage: 214.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2898041e-0cc7-420f-9363-73a3edc61e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate(df, col):\n",
    "    '''\n",
    "    dfのcolカラム内の欠損を区間ごとに線形補間する\n",
    "    '''\n",
    "    f = lambda g: g.interpolate(method='linear', axis=0)\n",
    "    \n",
    "    df.sort_values('datetime', inplace=True)\n",
    "    df[col] = df.groupby(['start_code', 'end_code'])[col].apply(f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    # 「年」情報を入れる\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    # 渋滞フラグ 0/1\n",
    "    df['jam_quantity'] = np.where(df['jam_quantity'] > 0, 1, 0)\n",
    "    # 方向を数値化\n",
    "    direction_map = {'上り': 0, '下り': 1}\n",
    "    df['direction'] = df['direction'].map(direction_map)\n",
    "    # 四半期を数値化\n",
    "    df['quarter'] = df['quarter'].str[-1]\n",
    "    # object型のカラムを落とす\n",
    "    drop_cols = ['road_code', 'weather_description', 'jam_type']\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # 速度の欠損を埋める\n",
    "    df = linear_interpolate(df, 'speed')\n",
    "    \n",
    "    # 型変換\n",
    "    type_map = {\n",
    "        'direction': np.uint8,\n",
    "        'quarter': np.uint8,\n",
    "        'jam_quantity': np.uint8,\n",
    "        'search_1h': int,\n",
    "        'search_unspec_1d': int,\n",
    "        'search_unspec_3d': int,\n",
    "        'search_unspec_7d': int,\n",
    "        'search_unspec_10d': int,\n",
    "        'allCars': np.float32,\n",
    "        'speed': np.float32,\n",
    "    }\n",
    "    df = df.astype(type_map)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9a480b6b-c458-4590-91b7-3452a081adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 551880 entries, 0 to 551879\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   datetime           551880 non-null  datetime64[ns]\n",
      " 1   index              551880 non-null  int64         \n",
      " 2   start_name         551880 non-null  object        \n",
      " 3   end_name           551880 non-null  object        \n",
      " 4   start_code         551880 non-null  object        \n",
      " 5   end_code           551880 non-null  object        \n",
      " 6   start_pref_code    551880 non-null  int64         \n",
      " 7   end_pref_code      551880 non-null  int64         \n",
      " 8   start_lat          551880 non-null  float64       \n",
      " 9   end_lat            551880 non-null  float64       \n",
      " 10  start_lng          551880 non-null  float64       \n",
      " 11  end_lng            551880 non-null  float64       \n",
      " 12  start_degree       551880 non-null  float64       \n",
      " 13  end_degree         551880 non-null  float64       \n",
      " 14  quarter            551880 non-null  uint8         \n",
      " 15  month              551880 non-null  int64         \n",
      " 16  day                551880 non-null  int64         \n",
      " 17  dayofweek          551880 non-null  int64         \n",
      " 18  is_holiday         551880 non-null  int64         \n",
      " 19  hour               551880 non-null  int64         \n",
      " 20  lane_count         551880 non-null  int64         \n",
      " 21  KP                 551880 non-null  float64       \n",
      " 22  direction          551880 non-null  uint8         \n",
      " 23  start_KP           551880 non-null  float64       \n",
      " 24  end_KP             551880 non-null  float64       \n",
      " 25  road_distance      551880 non-null  float64       \n",
      " 26  date               551880 non-null  object        \n",
      " 27  pressure           551880 non-null  float64       \n",
      " 28  rainfall           551880 non-null  float64       \n",
      " 29  temperature        551880 non-null  float64       \n",
      " 30  humidity           551880 non-null  float64       \n",
      " 31  wind_speed         551880 non-null  float64       \n",
      " 32  daylight_hours     551880 non-null  float64       \n",
      " 33  snowfall           551880 non-null  float64       \n",
      " 34  deepest_snowfall   551880 non-null  float64       \n",
      " 35  degree_sum         551880 non-null  float64       \n",
      " 36  limit_speed        551880 non-null  int64         \n",
      " 37  distance           551880 non-null  float64       \n",
      " 38  search_5min        551880 non-null  float64       \n",
      " 39  search_1h          551880 non-null  int64         \n",
      " 40  search_unspec_1d   551880 non-null  int64         \n",
      " 41  search_unspec_3d   551880 non-null  int64         \n",
      " 42  search_unspec_7d   551880 non-null  int64         \n",
      " 43  search_unspec_10d  551880 non-null  int64         \n",
      " 44  allCars            551880 non-null  float32       \n",
      " 45  jam_quantity       551880 non-null  uint8         \n",
      " 46  OCC                551880 non-null  float64       \n",
      " 47  speed              551880 non-null  float32       \n",
      " 48  year               551880 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float32(2), float64(22), int64(16), object(5), uint8(3)\n",
      "memory usage: 195.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test = preprocess(df_test.copy())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0b39c58f-57dc-48c9-a557-0f5e71ead960",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_col = ['datetime', 'start_name', 'end_name']\n",
    "features = [\n",
    "    'hour', 'dayofweek', 'is_holiday', 'lane_count', \n",
    "    'search_1h', 'search_unspec_1d', 'allCars'\n",
    "]\n",
    "target = 'allCars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "dbce3814-436d-4547-a3fb-479f7fc14c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 8760, 7) (63, 8760)\n"
     ]
    }
   ],
   "source": [
    "# 特徴量を絞る\n",
    "df_X = df_test.loc[:, key_col + features]\n",
    "df_y = df_test.loc[:, target]\n",
    "\n",
    "# データ数\n",
    "N = df_X.shape[0]\n",
    "# 時系列長\n",
    "N_period = df_X.drop_duplicates(\"datetime\").shape[0]\n",
    "# 区間数\n",
    "N_sec = df_X.drop_duplicates([\"start_name\", \"end_name\"]).shape[0]\n",
    "# 特徴量数\n",
    "D = len(features)\n",
    "\n",
    "# numpy配列を準備\n",
    "X = np.empty((N_sec, N_period, D), dtype=np.float32)\n",
    "y = np.empty((N_sec, N_period), dtype=np.float32)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1174144f-e6b7-4b14-a513-239091d39383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 8760, 7) (63, 8760)\n"
     ]
    }
   ],
   "source": [
    "# 区間別に時系列情報をnumpy配列に格納する\n",
    "group = df_X.groupby(['start_name', 'end_name'])\n",
    "for i, (g_key, df_g) in enumerate(group):\n",
    "    X[i] = df_g.loc[:, features].values\n",
    "    y[i] = df_g.loc[:, target].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3ae885c7-444a-4ceb-be4c-2dc48a2248a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_norm = X.transform(X)\n",
    "X_mean = X.reshape(-1, D).mean(axis=0)\n",
    "X_std = X.reshape(-1, D).std(axis=0)\n",
    "\n",
    "X_norm = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d636d6b7-b897-4c86-b1a3-cfa44ea2b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 7008, 7) (63, 7008)\n",
      "(63, 1752, 7) (63, 1752)\n"
     ]
    }
   ],
   "source": [
    "# train, validに分割\n",
    "train_ratio = 0.8\n",
    "ind_split = int(X_norm.shape[1] * train_ratio)\n",
    "X_train, X_val = X_norm[:, :ind_split], X_norm[:, ind_split:]\n",
    "y_train, y_val = y[:, :ind_split], y[:, ind_split:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0ae3bdf2-b682-49cf-bad4-efe91f223d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-B-C-D x 各区間10個ずつ\n",
    "# batch_size = 2\n",
    "# time_step = 3\n",
    "\n",
    "# AB0, AB1, AB2, ..., AB9\n",
    "# BC0, BC1, BC2, ..., BC9\n",
    "# CD0, CD1, CD2, ..., CD9\n",
    "\n",
    "# ABに限定するのであれば\n",
    "# [AB0, AB1, AB2], [AB1, AB2, AB3], ..., [AB7, AB8, AB9] -> 7個できる\n",
    "\n",
    "# バッチ数を区間数の倍数にすればいい？\n",
    "# [[AB0, AB1, AB2]\n",
    "# [BC0, BC1, BC2]\n",
    "# [CD0, CD1, CD2]]\n",
    "\n",
    "# 下みたいに区間に対応するラベルさえしっかり出力できるなら問題ない\n",
    "# [[AB0, AB1, AB2] -> AB3\n",
    "# [AB1, AB2, AB3] -> AB4\n",
    "# [AB5, AB6, AB7] -> AB8\n",
    "# [BC2, BC3, BC4] -> BC5\n",
    "# [BC7, BC8, BC9] -> BC10\n",
    "# [CD0, CD1, CD2]] -> CD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ebfa37b1-5392-4960-92b5-caa873f73718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM用のtime step, 区間のstackの処理はdatasetに投げる\n",
    "# dataloaderはミニバッチに区切るだけ\n",
    "class LSTMData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_X, data_y, time_step):\n",
    "        X, y = self.__sliding_window(data_X, data_y, time_step)       \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_step = time_step\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    \n",
    "    def __sliding_window(self, data_X, data_y, time_step):\n",
    "        N_sections, N_periods, _ = data_X.shape\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for i in range(N_sections):\n",
    "            # 各区間ごとにtime step分だけ切り出す\n",
    "            for t in range(time_step, N_periods-24):\n",
    "                time_pred = t + 24\n",
    "                time_input = (t - time_step, t + time_step + 1)\n",
    "                x_ = data_X[i, time_input[0] : time_input[1]]\n",
    "                y_ = data_y[i, time_pred]\n",
    "                X.append(x_)\n",
    "                y.append(y_)\n",
    "        \n",
    "        X = torch.from_numpy(np.array(X, dtype=np.float32))\n",
    "        y = torch.from_numpy(np.array(y, dtype=np.float32))\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "43a17bfe-5110-4967-9810-f2b11c7bddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, num_layers, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hid_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outs, (h, c) = self.lstm(x)\n",
    "        out = self.fc(h[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b8d9c737-7283-4dc1-9425-a50759155593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device=device)\n",
    "            target = target.unsqueeze(1).to(device=device)\n",
    "            \n",
    "            out = model(data)\n",
    "            loss = loss_fn(out, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data = data.to(device=device)\n",
    "                target = target.unsqueeze(1).to(device=device)\n",
    "\n",
    "                out = model(data)\n",
    "                loss = loss_fn(out, target)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        \n",
    "        if epoch <= 3 or epoch % 50 == 0:\n",
    "            log = f'{dt.datetime.now()} | Epoch: {epoch}, Train Loss: {train_loss / len(train_loader)}, Valid Loss: {val_loss / len(val_loader)}'\n",
    "            print(log)\n",
    "            \n",
    "            with open('./logs_cars.txt', mode='a') as f:\n",
    "                f.write(log + '\\n')\n",
    "        \n",
    "    return train_losses, val_losses\n",
    "            \n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_dict = {\n",
    "        'train': [],\n",
    "        'valid': []\n",
    "    }\n",
    "    for name, loader in [('train', train_loader), ('valid', val_loader)]:    \n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            for data, target in loader:\n",
    "                data = data.to(device=device)\n",
    "                target = target.unsqueeze(1).to(device=device)\n",
    "                \n",
    "                out = model(data)\n",
    "                loss = loss_fn(out, target)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                loss_dict[name].append(loss.item())\n",
    "               \n",
    "            print(f'{name} Accuracy: {total_loss / len(loader) :.3f}')\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d38b95f0-a275-4c54-96aa-64212e3d5f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (435456,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [272]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m72\u001b[39m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dataset_valid \u001b[38;5;241m=\u001b[39m LSTMData(X_val, y_val, time_step)\n\u001b[1;32m      7\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [256]\u001b[0m, in \u001b[0;36mLSTMData.__init__\u001b[0;34m(self, data_X, data_y, time_step)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_X, data_y, time_step):\n\u001b[0;32m----> 5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sliding_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m       \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n",
      "Input \u001b[0;32mIn [256]\u001b[0m, in \u001b[0;36mLSTMData.__sliding_window\u001b[0;34m(self, data_X, data_y, time_step)\u001b[0m\n\u001b[1;32m     31\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(x_)\n\u001b[1;32m     32\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(y_)\n\u001b[0;32m---> 34\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (435456,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "time_step = 12\n",
    "batch_size = 256\n",
    "\n",
    "dataset_train = LSTMData(X_train, y_train, time_step)\n",
    "dataset_valid = LSTMData(X_val, y_val, time_step)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7100d936-bee1-4285-a69a-9b0f875d4d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 06:26:44.726327 | Epoch: 1, Train Loss: 701.118201507817, Valid Loss: 569.7277440581341\n",
      "2022-07-29 06:27:04.840942 | Epoch: 2, Train Loss: 412.72040981741253, Valid Loss: 349.06383685998316\n",
      "2022-07-29 06:27:24.983631 | Epoch: 3, Train Loss: 249.73654300592, Valid Loss: 225.93696834817922\n",
      "2022-07-29 06:43:05.151815 | Epoch: 50, Train Loss: 71.51413224212504, Valid Loss: 104.53039212813442\n",
      "2022-07-29 06:59:39.526602 | Epoch: 100, Train Loss: 65.74369836880525, Valid Loss: 106.08162309198677\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "in_dim = D\n",
    "hid_dim = 100\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "train_losses, val_losses = train(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "afb674a8-cb27-4040-ae77-1b140045fe1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(range(len(train_losses)), train_losses)\n",
    "ax.plot(range(len(val_losses)), val_losses)\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_ylim(0, 1e3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "313512b5-4c4d-48aa-ba0f-63c3d3e74035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy: 64.414\n",
      "valid Accuracy: 106.082\n"
     ]
    }
   ],
   "source": [
    "loss_dict = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "70220b82-63db-44ff-94e5-670621ccdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = df_test[(df_test['start_name'] == '鶴ヶ島') & (df_test['direction'] == 1)]\n",
    "tmp_train = tmp_train.loc[:, key_col + features]\n",
    "\n",
    "# 時系列長\n",
    "N_period = tmp_train.drop_duplicates(\"datetime\").shape[0]\n",
    "# 区間数\n",
    "N_sec = tmp_train.drop_duplicates([\"start_name\", \"end_name\"]).shape[0]\n",
    "# 特徴量数\n",
    "D = len(features)\n",
    "\n",
    "tmp_train_value = tmp_train[features].values.reshape(1, N_period, D)\n",
    "tmp_train_norm = (tmp_train_value - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2c6c00c2-90d7-4da0-963f-7f631e0a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X = []\n",
    "\n",
    "for i in range(N_sec):\n",
    "    for t in range(time_step, N_period - 24):\n",
    "        time_pred = t + 24\n",
    "        time_input = (t - time_step, t + time_step + 1)\n",
    "        x_ = tmp_train_norm[i, time_input[0] : time_input[1]]\n",
    "        tmp_X.append(x_)\n",
    "\n",
    "tmp_X = torch.from_numpy(np.array(tmp_X, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f1369b62-c2ce-4512-a50c-e050ade2ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model(tmp_X.to(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "741a600e-c0c8-4e35-ab44-0070998eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.arange(time_step, N_period - 24) + 24\n",
    "tmp_y = tmp_train.iloc[ys, -1].values.reshape(-1, 1)\n",
    "tmp_y = torch.from_numpy(tmp_y).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "75c7908b-8ca8-45f2-ab77-9f9571a38319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2830.],\n",
       "        [2699.],\n",
       "        [2518.],\n",
       "        [2320.],\n",
       "        [2056.],\n",
       "        [1892.],\n",
       "        [1657.],\n",
       "        [1534.],\n",
       "        [1343.],\n",
       "        [ 890.]], device='cuda:0')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bfc7632f-df57-4347-a9e6-bf336e0cfdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1906.3523],\n",
       "        [2111.0740],\n",
       "        [1478.2659],\n",
       "        [1709.9409],\n",
       "        [1561.3125],\n",
       "        [1184.2350],\n",
       "        [1547.8439],\n",
       "        [1354.0841],\n",
       "        [ 719.4714],\n",
       "        [ 688.2144]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1f122439-cf23-4510-9a91-ab1dfab22159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1 -------\n",
      "tensor(126.)\n",
      "tensor([115.0645], device='cuda:0')\n",
      "10.935508728027344\n",
      "\n",
      "------- 2 -------\n",
      "tensor(134.)\n",
      "tensor([134.9498], device='cuda:0')\n",
      "0.9497833251953125\n",
      "\n",
      "------- 3 -------\n",
      "tensor(170.)\n",
      "tensor([168.9665], device='cuda:0')\n",
      "1.0334625244140625\n",
      "\n",
      "------- 4 -------\n",
      "tensor(198.)\n",
      "tensor([204.4083], device='cuda:0')\n",
      "6.4083099365234375\n",
      "\n",
      "------- 5 -------\n",
      "tensor(179.)\n",
      "tensor([184.3132], device='cuda:0')\n",
      "5.313201904296875\n",
      "\n",
      "------- 6 -------\n",
      "tensor(202.)\n",
      "tensor([209.7910], device='cuda:0')\n",
      "7.79095458984375\n",
      "\n",
      "------- 7 -------\n",
      "tensor(224.)\n",
      "tensor([240.2662], device='cuda:0')\n",
      "16.266204833984375\n",
      "\n",
      "------- 8 -------\n",
      "tensor(317.)\n",
      "tensor([303.8457], device='cuda:0')\n",
      "13.154327392578125\n",
      "\n",
      "------- 9 -------\n",
      "tensor(383.)\n",
      "tensor([374.0816], device='cuda:0')\n",
      "8.918426513671875\n",
      "\n",
      "------- 10 -------\n",
      "tensor(440.)\n",
      "tensor([439.5305], device='cuda:0')\n",
      "0.469482421875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65/1850680170.py:11: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for data, target in dataset_train:\n",
    "        if i >= 10:\n",
    "            break\n",
    "        i += 1\n",
    "        print(f'------- {i} -------')\n",
    "        out = model(data.to(device=device))\n",
    "        print(target)\n",
    "        print(out)\n",
    "        print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "105cdb92-cd84-4abb-97f8-65ea5a5f3cf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:24:34.155558 | Epoch 1 | Loss: 65953.34375\n",
      "2022-07-21 17:24:40.475783 | Epoch 2 | Loss: 6871.1943359375\n",
      "2022-07-21 17:24:46.874386 | Epoch 3 | Loss: 11021.1640625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [339]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     15\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     17\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     18\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 3000\n",
    "in_dim = X_train.shape[-1]\n",
    "hid_dim = 100\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device=device)\n",
    "        target = target.unsqueeze(1).to(device=device)\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch < 3 or (epoch + 1) % 100 == 0:\n",
    "        print(f'{dt.datetime.now()} | Epoch {epoch+1} | Loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
