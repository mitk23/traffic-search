{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f9b686-4dee-4846-b006-9d3b39292662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.scaler import STMatrixStandardScaler\n",
    "from utils.helper import format_stmatrix, train_test_split, fix_seed\n",
    "from dataset import STDataset\n",
    "from trainer import Trainer\n",
    "from logger import Logger\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a66af52-fa9b-44a1-8e3d-7c1ab733e773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f0112-9df1-4430-a141-c4b94a5a4962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 前処理してデータセットを作成\n",
    "- 渋滞量 -> フラグに変換\n",
    "- 方向 -> 0/1に変換\n",
    "    - 上り: 0, 下り: 1\n",
    "- 四半期を数値化\n",
    "- 使用しないカラムを落とす\n",
    "    - 天気 + `index`, `data`, `road_code`, `jam_type`\n",
    "- 速度の欠損を埋める\n",
    "- OCC -> [0, 1]に変換\n",
    "- 型変換\n",
    "    - float64 -> float32\n",
    "    - 区間の名前, コード, 県コード, 0/1系, カレンダーデータをcategoryデータに\n",
    "    - degreeをint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529b47c5-ece1-4061-b622-f0c26c9de6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 道路名\n",
    "# TARGET_ROAD='tateyama'\n",
    "TARGET_ROAD='kannetsu'\n",
    "\n",
    "# 交通量\n",
    "PROCESSED_DATA_DIR = '../Input_processed_data'\n",
    "TRAFFIC_DIR = f'{PROCESSED_DATA_DIR}/traffic'\n",
    "TRAFFIC_CSV = f'{TRAFFIC_DIR}/{TARGET_ROAD}_20220621all-merged_filled_1h.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b58e808-e64e-4d7d-836d-04fd532a1054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_types = {'start_code': str, 'end_code': str, 'road_code': str, 'jam_type': str,}\n",
    "\n",
    "df = pd.read_csv(TRAFFIC_CSV, parse_dates=True, index_col='datetime', dtype=col_types).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2898041e-0cc7-420f-9363-73a3edc61e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate(df, col):\n",
    "    '''\n",
    "    dfのcolカラム内の欠損を区間ごとに線形補間する\n",
    "    '''\n",
    "    f = lambda g: g.interpolate(method='linear', axis=0)\n",
    "    \n",
    "    df.sort_values('datetime', inplace=True)\n",
    "    df[col] = df.groupby(['start_code', 'end_code'])[col].apply(f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    # 「年」情報を入れる\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    # 渋滞フラグ 0/1\n",
    "    df['jam_flag'] = np.where(df['speed'] < 40, 1, 0)\n",
    "    # 方向を数値化\n",
    "    direction_map = {'上り': 0, '下り': 1}\n",
    "    df['direction'] = df['direction'].map(direction_map)\n",
    "    # 四半期を数値化\n",
    "    df['quarter'] = df['quarter'].str[-1]\n",
    "    \n",
    "    # object型のカラム, いらないカラムを落とす\n",
    "    drop_cols = [\n",
    "        'index', 'date', 'road_code', 'pressure', 'rainfall', \n",
    "        'temperature', 'humidity', 'wind_speed', 'daylight_hours', \n",
    "        'snowfall', 'deepest_snowfall', 'weather_description', 'jam_type'\n",
    "    ]\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # 速度の欠損を埋める\n",
    "    df = linear_interpolate(df, 'speed')\n",
    "    # OCCを[0,1]に変換\n",
    "    df['OCC'] = df['OCC'] / 100.0\n",
    "    \n",
    "    # 型変換\n",
    "    f64_cols = df.select_dtypes(include=[np.float64]).columns\n",
    "    df.loc[:, f64_cols] = df.loc[:, f64_cols].astype(np.float32)\n",
    "    i64_cols = df.select_dtypes(include=[int]).columns\n",
    "    df.loc[:, i64_cols] = df.loc[:, i64_cols].astype(np.int32)\n",
    "    \n",
    "    type_map = {\n",
    "        'start_name': 'category',\n",
    "        'end_name': 'category',\n",
    "        'start_code': 'category',\n",
    "        'end_code': 'category',\n",
    "        'start_pref_code': 'category',\n",
    "        'end_pref_code': 'category',\n",
    "        'direction': 'category',\n",
    "        'month': 'category',\n",
    "        'day': 'category',\n",
    "        'dayofweek': 'category',\n",
    "        'is_holiday': 'category',\n",
    "        'hour': 'category',\n",
    "        'quarter': 'category',\n",
    "        'jam_quantity': 'category',\n",
    "        'start_degree': np.int32,\n",
    "        'end_degree': np.int32,\n",
    "        'degree_sum': np.int32,\n",
    "    }\n",
    "    df = df.astype(type_map)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23d5e8e-66a4-4c63-a76c-984f49cdec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, start_date, end_date, pkl_name):\n",
    "    tmp = df.loc[(df['datetime'] >= pd.Timestamp(start_date)) & (df['datetime'] < pd.Timestamp(end_date))]\n",
    "    # tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp = preprocess(tmp.copy())\n",
    "    tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp.to_pickle(pkl_name)\n",
    "\n",
    "# whole dataset\n",
    "start_date = '2021/4/2'\n",
    "end_date = '2022/6/1'\n",
    "pkl_name = f'./datasets/jam/kannetsu_210402-220531.pkl'\n",
    "\n",
    "create_dataset(df, start_date, end_date, pkl_name)\n",
    "\n",
    "# mini dataset\n",
    "start_date = '2021/4/2'\n",
    "end_date = '2021/6/1'\n",
    "pkl_name = './datasets/jam/kannetsu_210402-210531.pkl'\n",
    "\n",
    "create_dataset(df, start_date, end_date, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7f12-2979-4952-8165-d5c01122d1f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## データセットを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2840688e-38f3-4355-bd7e-e1655e966cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini\n",
    "df_test = pd.read_pickle('./datasets/jam/kannetsu_210402-210531.pkl')\n",
    "# whole\n",
    "df_all = pd.read_pickle('./datasets/jam/kannetsu_210402-220531.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a5f703-fc2c-4d76-9bb8-61bc9e565947",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_table = pd.read_pickle(f'{config.TABLES_DIR}/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle(f'{config.TABLES_DIR}/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9502253-a633-48b8-bc79-f90b5cf43d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>start_name</th>\n",
       "      <th>end_name</th>\n",
       "      <th>start_code</th>\n",
       "      <th>end_code</th>\n",
       "      <th>start_pref_code</th>\n",
       "      <th>end_pref_code</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>search_unspec_1d</th>\n",
       "      <th>search_unspec_3d</th>\n",
       "      <th>search_unspec_7d</th>\n",
       "      <th>search_unspec_10d</th>\n",
       "      <th>allCars</th>\n",
       "      <th>jam_quantity</th>\n",
       "      <th>OCC</th>\n",
       "      <th>speed</th>\n",
       "      <th>year</th>\n",
       "      <th>jam_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>所沢</td>\n",
       "      <td>大泉ＪＣＴ</td>\n",
       "      <td>1800006</td>\n",
       "      <td>1110210</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>35.806149</td>\n",
       "      <td>35.755821</td>\n",
       "      <td>139.535507</td>\n",
       "      <td>...</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>87.298416</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>小出</td>\n",
       "      <td>大和ＰＡ</td>\n",
       "      <td>1800156</td>\n",
       "      <td>1800151</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.213329</td>\n",
       "      <td>37.160999</td>\n",
       "      <td>138.975403</td>\n",
       "      <td>...</td>\n",
       "      <td>749.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.970146</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>六日町</td>\n",
       "      <td>塩沢石打</td>\n",
       "      <td>1800146</td>\n",
       "      <td>1800141</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.077942</td>\n",
       "      <td>36.990280</td>\n",
       "      <td>138.879288</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.633331</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime start_name end_name start_code end_code start_pref_code  \\\n",
       "0 2021-04-02         所沢    大泉ＪＣＴ    1800006  1110210              11   \n",
       "1 2021-04-02         小出     大和ＰＡ    1800156  1800151              15   \n",
       "2 2021-04-02        六日町     塩沢石打    1800146  1800141              15   \n",
       "\n",
       "  end_pref_code  start_lat    end_lat   start_lng  ...  search_unspec_1d  \\\n",
       "0            13  35.806149  35.755821  139.535507  ...            2156.0   \n",
       "1            15  37.213329  37.160999  138.975403  ...             749.0   \n",
       "2            15  37.077942  36.990280  138.879288  ...             705.0   \n",
       "\n",
       "   search_unspec_3d  search_unspec_7d search_unspec_10d allCars jam_quantity  \\\n",
       "0            2156.0            2156.0            2156.0   630.0            0   \n",
       "1             749.0             749.0             749.0    67.0            0   \n",
       "2             705.0             705.0             705.0    60.0            0   \n",
       "\n",
       "    OCC      speed  year  jam_flag  \n",
       "0  0.02  87.298416  2021         0  \n",
       "1  0.00  90.970146  2021         0  \n",
       "2  0.00  87.633331  2021         0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e4d66-8ae9-4d1a-a770-d55c4c82dfce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 時間, 区間にembedding用のIDを割り振る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91cfa6-79bd-4901-b38d-7e436704000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間情報を管理するためのテーブルを作成 (month x hour x dayofweeks x is_holidays)\n",
    "# months = range(1, 12+1)\n",
    "# hours = range(24)\n",
    "# dayofweeks = range(1, 7+1)\n",
    "# is_holidays = (0, 1)\n",
    "\n",
    "# dt_table = pd.DataFrame(itertools.product(months, hours, dayofweeks, is_holidays), columns=['month', 'hour', 'dayofweek', 'is_holiday'], dtype='category')\n",
    "# dt_table = dt_table.query('dayofweek not in (6, 7) | is_holiday != 0').reset_index(drop=True)\n",
    "# dt_table = dt_table.reset_index().set_index(['month', 'hour', 'dayofweek', 'is_holiday']).astype('category')\n",
    "\n",
    "# dt_table.to_pickle('./datasets/datetime_table.pkl')\n",
    "\n",
    "# dt_table = pd.read_pickle('./datasets/datetime_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48291632-a12e-4e3c-a8f5-9ba4e8f91aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間情報を管理するためのテーブルを作成 (hour x dayofweeks x is_holidays)\n",
    "# hours = range(24)\n",
    "# dayofweeks = range(1, 7+1)\n",
    "# is_holidays = (0, 1)\n",
    "\n",
    "# dt_table = pd.DataFrame(itertools.product(hours, dayofweeks, is_holidays), columns=['hour', 'dayofweek', 'is_holiday'], dtype='category')\n",
    "# dt_table = dt_table.query('dayofweek not in (6, 7) | is_holiday != 0').reset_index(drop=True)\n",
    "# dt_table = dt_table.reset_index().set_index(['hour', 'dayofweek', 'is_holiday']).astype('category')\n",
    "\n",
    "# dt_table.to_pickle('./datasets/mini_datetime_table.pkl')\n",
    "\n",
    "# dt_table = pd.read_pickle('./datasets/mini_datetime_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b54d50-3eba-4d3e-93ea-768d54c39097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区間情報を管理するためのテーブルを作成\n",
    "# sec_table = df_test[['start_name', 'end_name', 'direction', 'KP']].drop_duplicates()\n",
    "# 区間順にソート\n",
    "# sort_f = lambda g: g.sort_values('KP', ascending=(g.name == 1))\n",
    "# sec_table = sec_table.groupby('direction').apply(sort_f).reset_index(drop=True)\n",
    "\n",
    "# sec_table.to_pickle('./datasets/section_table.pkl')\n",
    "# sec_table.head(3)\n",
    "\n",
    "# sec_table = pd.read_pickle('./datasets/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7ac6bbd-5e5d-4daa-b997-400b4b7672f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2id(df, dt_table):\n",
    "    time_col = ['hour', 'dayofweek', 'is_holiday']\n",
    "    f = lambda g: g.assign(datetime_id=dt_table.loc[g.name, 'index'])\n",
    "    df = df.groupby(time_col).apply(f)\n",
    "    df['datetime_id'] = df['datetime_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def section2id(df, sec_table):\n",
    "    f = lambda g: g.assign(section_id=sec_table.query(f'start_name == \"{g.name[0]}\" & end_name == \"{g.name[1]}\"').index.item())\n",
    "    df = df.groupby(['start_name', 'end_name']).apply(f)\n",
    "    df['section_id'] = df['section_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def identify(df, dt_table, sec_table):\n",
    "    df = datetime2id(df, dt_table)\n",
    "    df = section2id(df, sec_table)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8ae9e67-47b0-4274-b963-edf85e4b3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = identify(df_test, dt_table, sec_table)\n",
    "df_test.to_pickle('./datasets/jam/kannetsu_210402-210531.pkl')\n",
    "\n",
    "df_all = identify(df_all, dt_table, sec_table)\n",
    "df_all.to_pickle('./datasets/jam/kannetsu_210402-220531.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a0e9b-14b1-434c-8de6-2aa603db4727",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Spatial Temporal Matrixに整形\n",
    "- 区間数 x 時系列数 の行列\n",
    "- 実際は 区間数 x 時系列数 x 特徴量数 のテンソル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "190b8871-8f2e-4a45-8523-ad908ed36a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mini\n",
    "# df_test = pd.read_pickle('./datasets/jam/kannetsu_210402-210531.pkl')\n",
    "# # whole\n",
    "# df_all = pd.read_pickle('./datasets/jam/kannetsu_210402-220531.pkl')\n",
    "\n",
    "# df_test_tr = df_test[df_test['datetime'] < pd.Timestamp('2021/5/20')].reset_index(drop=True)\n",
    "# df_test_va = df_test[df_test['datetime'] >= pd.Timestamp('2021/5/20')].reset_index(drop=True)\n",
    "# df_test_tr.to_pickle('./datasets/jam/kannetsu_210402-210519.pkl')\n",
    "# df_test_va.to_pickle('./datasets/jam/kannetsu_210520-210531.pkl')\n",
    "\n",
    "# df_all_tr = df_all[df_all['datetime'] < pd.Timestamp('2022/3/1')].reset_index(drop=True)\n",
    "# df_all_va = df_all[df_all['datetime'] >= pd.Timestamp('2022/3/1')].reset_index(drop=True)\n",
    "# df_all_tr.to_pickle('./datasets/jam/kannetsu_210402-220228.pkl')\n",
    "# df_all_va.to_pickle('./datasets/jam/kannetsu_220301-220531.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388e22b3-fa73-4af8-83ae-dad170795ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tr = pd.read_pickle('./datasets/jam/kannetsu_210402-210519.pkl')\n",
    "df_test_va = pd.read_pickle('./datasets/jam/kannetsu_210520-210531.pkl')\n",
    "\n",
    "df_all_tr = pd.read_pickle('./datasets/jam/kannetsu_210402-220228.pkl')\n",
    "df_all_va = pd.read_pickle('./datasets/jam/kannetsu_220301-220531.pkl')\n",
    "\n",
    "dt_table = pd.read_pickle(f'{config.TABLES_DIR}/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle(f'{config.TABLES_DIR}/section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b39c58f-57dc-48c9-a557-0f5e71ead960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 特徴量の元になる列\n",
    "time_col = ['datetime_id']\n",
    "section_col = ['section_id']\n",
    "search_col = ['search_1h', 'search_unspec_1d']\n",
    "traffic_col = ['allCars', 'speed', 'OCC', 'jam_quantity']\n",
    "\n",
    "feature_col = time_col + section_col + search_col + traffic_col\n",
    "\n",
    "# 予測対象\n",
    "target_col = 'jam_quantity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff68889-a006-45c5-9066-4188cdf219b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tr[target_col] = df_all_tr[target_col].astype(np.int64)\n",
    "df_all_va[target_col] = df_all_va[target_col].astype(np.int64)\n",
    "\n",
    "df_test_tr[target_col] = df_test_tr[target_col].astype(np.int64)\n",
    "df_test_va[target_col] = df_test_va[target_col].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cfca28-8fa1-49f8-a821-5b7c5f49d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1152, 63]) torch.Size([8, 288, 63]) torch.Size([1, 1152, 63]) torch.Size([1, 288, 63])\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr = format_stmatrix(df_test_tr, sec_table, feature_col, target_col)\n",
    "X_va, y_va = format_stmatrix(df_test_va, sec_table, feature_col, target_col)\n",
    "print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffac485-c759-4a8c-be33-a714e2b4ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(X_tr, './datasets/jam/features_train.pkl')\n",
    "# torch.save(X_va, './datasets/jam/features_test.pkl')\n",
    "# torch.save(y_tr, './datasets/jam/labels_train.pkl')\n",
    "# torch.save(y_va, './datasets/jam/labels_test.pkl')\n",
    "\n",
    "# torch.save(X_tr, './datasets/jam/mini_features_train.pkl')\n",
    "# torch.save(X_va, './datasets/jam/mini_features_test.pkl')\n",
    "# torch.save(y_tr, './datasets/jam/mini_labels_train.pkl')\n",
    "# torch.save(y_va, './datasets/jam/mini_labels_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376cb0a-2709-4e34-94af-8c23af4a418f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 標準化・正規化\n",
    "- 標準化を行う\n",
    "- 時間特徴量（`month`, `hour`, `day_of_week`）はsin, cosで変換するのもやってみる\n",
    "- 検索数, 台数は上り・下り別でもやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b43f0a-daa0-4011-8eb4-a3d1c155acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7992, 63]) torch.Size([8, 2208, 63])\n",
      "torch.Size([1, 7992, 63]) torch.Size([1, 2208, 63])\n"
     ]
    }
   ],
   "source": [
    "dt_table = pd.read_pickle(f'{config.TABLES_DIR}/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle(f'{config.TABLES_DIR}/section_table.pkl')\n",
    "\n",
    "X_tr = torch.load('./datasets/jam/features_train.pkl')\n",
    "X_va = torch.load('./datasets/jam/features_test.pkl')\n",
    "y_tr = torch.load('./datasets/jam/labels_train.pkl')\n",
    "y_va = torch.load('./datasets/jam/labels_test.pkl')\n",
    "\n",
    "# X_tr = torch.load('./datasets/jam/mini_features_train.pkl')\n",
    "# X_va = torch.load('./datasets/jam/mini_features_test.pkl')\n",
    "# y_tr = torch.load('./datasets/jam/mini_labels_train.pkl')\n",
    "# y_va = torch.load('./datasets/jam/mini_labels_test.pkl')\n",
    "\n",
    "print(X_tr.shape, X_va.shape)\n",
    "print(y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59f0469-e844-48d9-b897-4c4b2596f2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ID列は飛ばして標準化\n",
    "skip_features = [0, 1, -1]\n",
    "scaler = STMatrixStandardScaler(skip_features=skip_features)\n",
    "\n",
    "scaler.fit(X_tr)\n",
    "X_tr_norm = scaler.transform(X_tr)\n",
    "\n",
    "scaler.fit(X_va)\n",
    "X_va_norm = scaler.transform(X_va)\n",
    "\n",
    "# torch.save(X_tr_norm, './datasets/jam/mini_features_train_norm.pkl')\n",
    "# torch.save(X_va_norm, './datasets/jam/mini_features_test_norm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b4d27-83ee-4e74-8cbd-e2f88b5bc7e3",
   "metadata": {},
   "source": [
    "## データセットの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265d39fd-7d3b-47e2-96d6-aad31ba1ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 1) (63, 4)\n",
      "torch.Size([8, 7992, 63]) torch.Size([8, 2208, 63])\n",
      "torch.Size([1, 7992, 63]) torch.Size([1, 2208, 63])\n"
     ]
    }
   ],
   "source": [
    "dt_table = pd.read_pickle(f'{config.TABLES_DIR}/datetime_table.pkl')\n",
    "sec_table = pd.read_pickle(f'{config.TABLES_DIR}/section_table.pkl')\n",
    "\n",
    "X_tr = torch.load(f'{config.DATASET_DIR}/jam/features_train_norm.pkl')\n",
    "X_va = torch.load(f'{config.DATASET_DIR}/jam/features_test_norm.pkl')\n",
    "y_tr = torch.load(f'{config.DATASET_DIR}/jam/labels_train.pkl')\n",
    "y_va = torch.load(f'{config.DATASET_DIR}/jam/labels_test.pkl')\n",
    "\n",
    "# X_tr = torch.load(f'{config.MINI_DIR}/jam/mini_features_train_norm.pkl')\n",
    "# X_va = torch.load(f'{config.MINI_DIR}/jam/mini_features_test_norm.pkl')\n",
    "# y_tr = torch.load(f'{config.MINI_DIR}/jam/mini_labels_train.pkl')\n",
    "# y_va = torch.load(f'{config.MINI_DIR}/jam/mini_labels_test.pkl')\n",
    "\n",
    "print(dt_table.shape, sec_table.shape)\n",
    "print(X_tr.shape, X_va.shape)\n",
    "print(y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6731a3ac-b9fc-46dd-87d4-050fa49aee96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_step = 168\n",
    "prediction_horizon = 24\n",
    "space_window = (-2, 2)\n",
    "static_col = config.STATIC_COL\n",
    "\n",
    "dataset_train = STDataset(X_tr, y_tr, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)\n",
    "\n",
    "dataset_valid = STDataset(X_va, y_va, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340b55f-dcc6-4f86-a1d9-ed3c02faaaf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Networkの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3e7f1-34ea-4ac3-89be-9503a8dbc6bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97f15fb8-0331-4e92-89d2-5b16b9c2a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HA:\n",
    "    def forward(self, x):\n",
    "        out = x[:, -1].mean(dim=1)\n",
    "        return out\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68688362-29fa-473b-8071-f742d901baf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a17bfe-5110-4967-9810-f2b11c7bddfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, num_layers, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hid_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(x)\n",
    "        out = self.fc(h[0])\n",
    "        return out\n",
    "    \n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hid_dim, num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(1, hid_dim, num_layers, batch_first=batch_first)\n",
    "        self.search_lstm = nn.LSTM(2, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(x[..., -1:])\n",
    "        s_outs, (s_h, s_c) = self.search_lstm(x[..., -3:-1])\n",
    "        out = torch.cat([h[0], s_h[0]], dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66571ee8-675a-4eb0-b4b0-ebf2738a7725",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Embedding + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5c740-7ac7-4b2a-bbcd-03ffb1150fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Embedding(nn.Module):\n",
    "    def __init__(self, hid_dim, num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dt_n_embed = 32\n",
    "        self.road_n_embed = 16\n",
    "        self.n_embed = self.dt_n_embed + self.road_n_embed\n",
    "        self.dt_embed = nn.Embedding(len(dt_table), self.dt_n_embed)\n",
    "        self.road_embed = nn.Embedding(len(sec_table), self.road_n_embed)\n",
    "        \n",
    "        self.traffic_lstm = nn.LSTM(1, hid_dim, num_layers, batch_first=batch_first)\n",
    "        self.search_lstm = nn.LSTM(2, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        self.cat_fc = nn.Linear(self.n_embed, 16)\n",
    "        self.fc1 = nn.Linear(hid_dim * 2 + 16, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x_dy, x_st = x\n",
    "        \n",
    "        # categorical (datetime + road)\n",
    "        dt_emb = self.dt_embed(x_st[..., 0].to(dtype=torch.int64))\n",
    "        road_emb = self.road_embed(x_st[..., 1].to(dtype=torch.int64))\n",
    "        cat_emb = torch.cat([dt_emb, road_emb], dim=1)\n",
    "        cat_out = F.relu(self.cat_fc(cat_emb))\n",
    "        \n",
    "        # traffic\n",
    "        x_dy = x_dy.permute(0, 2, 1)\n",
    "        _, (traffic_h, _) = self.traffic_lstm(x_dy[..., -1:])\n",
    "        \n",
    "        # search\n",
    "        _, (search_h, _) = self.search_lstm(x_dy[..., -3:-1])\n",
    "        # linear\n",
    "        out = torch.cat([traffic_h[0], search_h[0], cat_out], dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e125-cdf0-4590-9817-bc3deff9ada1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conv1d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cff1d03-a345-40f5-8970-df8f0bc6d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dLSTM(nn.Module):\n",
    "    def __init__(self, hid_dim, kernel_size, num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.conv = nn.Conv1d(96, 96, 5)\n",
    "        self.lstm = nn.LSTM(1, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        self.search_conv1 = nn.Conv1d(96, 96, 5)\n",
    "        self.search_conv2 = nn.Conv1d(96, 96, 5)\n",
    "        self.search_fc = nn.Linear(96*2, 64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hid_dim + 64, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, D, T, S = x.shape\n",
    "        \n",
    "        # traffic\n",
    "        out = F.relu(self.conv(x[:, -1]))\n",
    "        _, (h, c) = self.lstm(out)\n",
    "        \n",
    "        # search\n",
    "        s_out1 = F.relu(self.search_conv1(x[:, -3]))\n",
    "        s_out1 = s_out1.view(N, -1)\n",
    "        s_out2 = F.relu(self.search_conv2(x[:, -2]))\n",
    "        s_out2 = s_out2.view(N, -1)\n",
    "        s_out = torch.cat([s_out1, s_out2], dim=1)\n",
    "        s_out = F.relu(self.search_fc(s_out))\n",
    "        \n",
    "        # concat\n",
    "        out = torch.cat([h[0], s_out], dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097cac43-51a8-4f97-86df-21fba6e57ca0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conv2d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806342f-9e74-435a-95de-eb5606575288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dLSTM(nn.Module):\n",
    "    def __init__(self, hid_dim, kernel_size, num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.padding = (4, 0)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, (9, 3), padding=self.padding)\n",
    "        self.conv2 = nn.Conv2d(32, 16, (9, 3), padding=self.padding)\n",
    "        self.lstm = nn.LSTM(16, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        self.search_conv1 = nn.Conv2d(2, 64, (9, 3), padding=self.padding)\n",
    "        self.search_conv2 = nn.Conv2d(64, 32, (9, 3), padding=self.padding)\n",
    "        self.search_fc = nn.Linear(32 * 96, 64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hid_dim + 64, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, D, T, S = x.shape   \n",
    "        # traffic\n",
    "        out = F.relu(self.conv1(x[:, -1:]))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out[..., 0].permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(out)\n",
    "        \n",
    "        # search feature\n",
    "        s_out = F.relu(self.search_conv1(x[:, -3:-1]))\n",
    "        s_out = F.relu(self.search_conv2(s_out))\n",
    "        s_out = s_out.view(N, -1)\n",
    "        s_out = F.relu(self.search_fc(s_out))\n",
    "        \n",
    "        # predict\n",
    "        out = torch.cat([h[0], s_out], dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51dab4-9100-4b0c-b7de-ec0801fc9f9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding + Conv2d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45890ff-5a2a-4c56-b3f5-71c4886ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal\n",
    "# EMB_DIM = 16\n",
    "# CONV_DIM = 32 # 32->16\n",
    "# LSTM_DIM = 64\n",
    "# LSTM_LAYERS = 1\n",
    "# SEARCH_CONV_DIM = 64 # 64->32\n",
    "# SEARCH_FC_DIM = 32\n",
    "# FC1_DIM = 32\n",
    "\n",
    "# wide\n",
    "EMB_DIM = 16\n",
    "CONV_DIM = 64\n",
    "LSTM_DIM = 64\n",
    "LSTM_LAYERS = 1\n",
    "SEARCH_CONV_DIM = 64\n",
    "SEARCH_FC_DIM = 128\n",
    "FC1_DIM = 64\n",
    "\n",
    "# wide2\n",
    "# EMB_DIM = 16\n",
    "# CONV_DIM = 64\n",
    "# LSTM_DIM = 128\n",
    "# LSTM_LAYERS = 2\n",
    "# SEARCH_CONV_DIM = 64\n",
    "# SEARCH_FC_DIM = 128\n",
    "# FC1_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab342350-7af9-4c19-9f91-d9d40422ebc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2dLSTM_Embedding(nn.Module):\n",
    "    def __init__(self, hid_dim, kernel_size, padding=(4,0), num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.padding = padding\n",
    "        \n",
    "        # categorical\n",
    "        self.dt_n_embed = 32\n",
    "        self.road_n_embed = 16\n",
    "        self.n_embed = self.dt_n_embed + self.road_n_embed\n",
    "        self.dt_embed = nn.Embedding(len(dt_table), self.dt_n_embed)\n",
    "        self.road_embed = nn.Embedding(len(sec_table), self.road_n_embed)\n",
    "        self.cat_fc = nn.Linear(self.n_embed, EMB_DIM)\n",
    "        self.cat_bn = nn.BatchNorm1d(EMB_DIM)\n",
    "        \n",
    "        # traffic\n",
    "        self.conv1 = nn.Conv2d(4, CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.bn1 = nn.BatchNorm2d(CONV_DIM)\n",
    "        self.conv2 = nn.Conv2d(CONV_DIM, CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.bn2 = nn.BatchNorm2d(CONV_DIM)\n",
    "        self.lstm = nn.LSTM(CONV_DIM, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        # search\n",
    "        self.search_conv1 = nn.Conv2d(2, SEARCH_CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.search_bn1 = nn.BatchNorm2d(SEARCH_CONV_DIM)\n",
    "        self.search_conv2 = nn.Conv2d(SEARCH_CONV_DIM, SEARCH_CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.search_bn2 = nn.BatchNorm2d(SEARCH_CONV_DIM)\n",
    "        self.search_fc = nn.Linear(SEARCH_CONV_DIM * 168, SEARCH_FC_DIM)\n",
    "        self.search_bn3 = nn.BatchNorm1d(SEARCH_FC_DIM)\n",
    "        \n",
    "        # linear (traffic + search + categorical)\n",
    "        self.fc1 = nn.Linear(hid_dim + SEARCH_FC_DIM + EMB_DIM, FC1_DIM)\n",
    "        self.bn3 = nn.BatchNorm1d(FC1_DIM)\n",
    "        self.fc2 = nn.Linear(FC1_DIM, 2)\n",
    "        \n",
    "        # dropout\n",
    "        self.embed_dropout = nn.Dropout(p=0.6)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.last_dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x_dy, x_st = x\n",
    "        N, D, T, S = x_dy.shape\n",
    "        \n",
    "        # categorical (datetime + road)\n",
    "        dt_emb = self.dt_embed(x_st[..., 0].to(dtype=torch.int64))\n",
    "        road_emb = self.road_embed(x_st[..., 1].to(dtype=torch.int64))\n",
    "        cat_emb = torch.cat([dt_emb, road_emb], dim=1)\n",
    "        cat_out = F.relu(self.cat_bn(self.cat_fc(cat_emb)))\n",
    "        cat_out = self.embed_dropout(cat_out)\n",
    "        \n",
    "        # traffic\n",
    "        out = F.relu(self.bn1(self.conv1(x_dy[:, -4:])))\n",
    "        # out = self.dropout(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # out = self.dropout(out)\n",
    "        out = out[..., 0].permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(out)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # search\n",
    "        s_out = F.relu(self.search_bn1(self.search_conv1(x_dy[:, -6:-4])))\n",
    "        s_out = F.relu(self.search_bn2(self.search_conv2(s_out)))\n",
    "        # s_out = self.dropout(s_out)\n",
    "        s_out = s_out.view(N, -1)\n",
    "        s_out = F.relu(self.search_bn3(self.search_fc(s_out)))\n",
    "        s_out = self.dropout(s_out)\n",
    "        \n",
    "        # linear\n",
    "        out = torch.cat([h[0], s_out, cat_out], dim=1)\n",
    "        out = F.relu(self.bn3(self.fc1(out)))\n",
    "        out = self.last_dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d0ac97d-6719-4879-acf5-9070a1e16dc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2dLSTM_Embedding(nn.Module):\n",
    "    def __init__(self, hid_dim, kernel_size, padding=(4,0), num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.padding = padding\n",
    "        \n",
    "        # categorical\n",
    "        self.dt_n_embed = 32\n",
    "        self.road_n_embed = 16\n",
    "        self.n_embed = self.dt_n_embed + self.road_n_embed\n",
    "        self.dt_embed = nn.Embedding(len(dt_table), self.dt_n_embed)\n",
    "        self.road_embed = nn.Embedding(len(sec_table), self.road_n_embed)\n",
    "        self.cat_fc = nn.Linear(self.n_embed, EMB_DIM)\n",
    "        self.cat_bn = nn.BatchNorm1d(EMB_DIM)\n",
    "        \n",
    "        # traffic\n",
    "        self.conv1 = nn.Conv2d(4, CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.bn1 = nn.BatchNorm2d(CONV_DIM)\n",
    "        self.conv2 = nn.Conv2d(CONV_DIM, CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.bn2 = nn.BatchNorm2d(CONV_DIM)\n",
    "        self.lstm = nn.LSTM(CONV_DIM, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        # search\n",
    "        self.search_conv1 = nn.Conv2d(2, SEARCH_CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.search_bn1 = nn.BatchNorm2d(SEARCH_CONV_DIM)\n",
    "        self.search_conv2 = nn.Conv2d(SEARCH_CONV_DIM, SEARCH_CONV_DIM, (9, 3), padding=self.padding)\n",
    "        self.search_bn2 = nn.BatchNorm2d(SEARCH_CONV_DIM)\n",
    "        self.search_fc = nn.Linear(SEARCH_CONV_DIM * 168, SEARCH_FC_DIM)\n",
    "        self.search_bn3 = nn.BatchNorm1d(SEARCH_FC_DIM)\n",
    "        \n",
    "        # linear (traffic + search + categorical)\n",
    "        self.fc1 = nn.Linear(hid_dim + SEARCH_FC_DIM + EMB_DIM, FC1_DIM)\n",
    "        self.bn3 = nn.BatchNorm1d(FC1_DIM)\n",
    "        self.fc2 = nn.Linear(FC1_DIM, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x_dy, x_st = x\n",
    "        N, D, T, S = x_dy.shape\n",
    "        \n",
    "        # categorical (datetime + road)\n",
    "        dt_emb = self.dt_embed(x_st[..., 0].to(dtype=torch.int64))\n",
    "        road_emb = self.road_embed(x_st[..., 1].to(dtype=torch.int64))\n",
    "        cat_emb = torch.cat([dt_emb, road_emb], dim=1)\n",
    "        cat_out = F.relu(self.cat_bn(self.cat_fc(cat_emb)))\n",
    "        \n",
    "        # traffic\n",
    "        out = F.relu(self.bn1(self.conv1(x_dy[:, -4:])))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = out[..., 0].permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(out)\n",
    "        \n",
    "        # search\n",
    "        s_out = F.relu(self.search_bn1(self.search_conv1(x_dy[:, -6:-4])))\n",
    "        s_out = F.relu(self.search_bn2(self.search_conv2(s_out)))\n",
    "        s_out = s_out.view(N, -1)\n",
    "        s_out = F.relu(self.search_bn3(self.search_fc(s_out)))\n",
    "        \n",
    "        # linear\n",
    "        out = torch.cat([h[0], s_out, cat_out], dim=1)\n",
    "        out = F.relu(self.bn3(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4d691f-225e-4a0d-b66a-915f90746fe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2dLSTM_Embedding(nn.Module):\n",
    "    def __init__(self, hid_dim, kernel_size, padding=(4,0), num_layers=1, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.padding = padding\n",
    "        \n",
    "        # categorical\n",
    "        self.dt_n_embed = 32\n",
    "        self.road_n_embed = 16\n",
    "        self.n_embed = self.dt_n_embed + self.road_n_embed\n",
    "        self.dt_embed = nn.Embedding(len(dt_table), self.dt_n_embed)\n",
    "        self.road_embed = nn.Embedding(len(sec_table), self.road_n_embed)\n",
    "        self.cat_fc = nn.Linear(self.n_embed, 16)\n",
    "        \n",
    "        # traffic\n",
    "        self.conv1 = nn.Conv2d(4, 32, (9, 3), padding=self.padding)\n",
    "        self.conv2 = nn.Conv2d(32, 16, (9, 3), padding=self.padding)\n",
    "        self.lstm = nn.LSTM(16, hid_dim, num_layers, batch_first=batch_first)\n",
    "        \n",
    "        # search\n",
    "        self.search_conv1 = nn.Conv2d(2, 64, (9, 3), padding=self.padding)\n",
    "        self.search_conv2 = nn.Conv2d(64, 32, (9, 3), padding=self.padding)\n",
    "        self.search_fc = nn.Linear(32 * 168, 64)\n",
    "        \n",
    "        # linear (traffic + search + categorical)\n",
    "        self.fc1 = nn.Linear(hid_dim + 64 + 16, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x_dy, x_st = x\n",
    "        N, D, T, S = x_dy.shape\n",
    "        \n",
    "        # categorical (datetime + road)\n",
    "        dt_emb = self.dt_embed(x_st[..., 0].to(dtype=torch.int64))\n",
    "        road_emb = self.road_embed(x_st[..., 1].to(dtype=torch.int64))\n",
    "        cat_emb = torch.cat([dt_emb, road_emb], dim=1)\n",
    "        cat_out = F.relu(self.cat_fc(cat_emb))\n",
    "        \n",
    "        # traffic\n",
    "        out = F.relu(self.conv1(x_dy[:, -4:]))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out[..., 0].permute(0, 2, 1)\n",
    "        outs, (h, c) = self.lstm(out)\n",
    "        \n",
    "        # search\n",
    "        s_out = F.relu(self.search_conv1(x_dy[:, -6:-4]))\n",
    "        s_out = F.relu(self.search_conv2(s_out))\n",
    "        s_out = s_out.view(N, -1)\n",
    "        s_out = F.relu(self.search_fc(s_out))\n",
    "        \n",
    "        # linear\n",
    "        out = torch.cat([h[0], s_out, cat_out], dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41aa92-6edb-4ee7-940c-990101e90046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374b51aa-84d2-4c9d-89f3-cfd0e80bb358",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        device=None,\n",
    "        logger=None,\n",
    "        model_name=None,\n",
    "    ):\n",
    "        super().__init__(model, optimizer, loss_fn, device, logger, model_name)\n",
    "\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.best_acc = 0.0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        n_epochs,\n",
    "        log_steps=None,\n",
    "        max_first_log_steps=3,\n",
    "        max_time=None,\n",
    "        save_epoch_steps=None,\n",
    "        random_seed=config.RANDOM_SEED,\n",
    "    ):\n",
    "        fix_seed(random_seed)\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            ## increment epoch\n",
    "            self.current_epoch += 1\n",
    "\n",
    "            ## train\n",
    "            self.model.train()\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            train_loss, train_acc = self.__train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accs.append(train_acc)\n",
    "            \n",
    "            train_time = time.time() - epoch_start\n",
    "\n",
    "            ## validate\n",
    "            self.model.eval()\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            val_loss, val_acc = self.__valid_epoch(val_loader)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accs.append(val_acc)\n",
    "\n",
    "            val_time = time.time() - epoch_start\n",
    "\n",
    "            ## logging\n",
    "            log_flag = (self.logger is not None) and (log_steps is not None)\n",
    "            if log_flag and (\n",
    "                (self.current_epoch <= max_first_log_steps)\n",
    "                or (self.current_epoch % log_steps == 0)\n",
    "            ):\n",
    "                message = f\"Epoch: {self.current_epoch} | Train Loss: {train_loss:.3f}, Train F1: {train_acc:.3f}, Train Time: {train_time:.2f} [sec] | Valid Loss: {val_loss:.3f}, Valid F1: {val_acc:.3f}, Valid Time: {val_time:.2f} [sec]\"\n",
    "                self.__logging(message)\n",
    "\n",
    "            if (self.model_name is not None) and (val_acc > self.best_acc):\n",
    "                self.best_acc = val_acc\n",
    "                self.save(self.model_name)\n",
    "\n",
    "            ## early stopping\n",
    "            if (max_time is not None) and (time.time() - start >= max_time):\n",
    "                break\n",
    "\n",
    "        return self.train_losses, self.val_losses\n",
    "\n",
    "    def validate(self, loader):\n",
    "        \"\"\"1epochだけ回して性能を評価\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        total_loss, total_acc = self.__valid_epoch(loader)\n",
    "        return total_loss, total_acc\n",
    "\n",
    "    def predict(self):\n",
    "        return\n",
    "\n",
    "    def __train_epoch(self, loader):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        ep_target = []\n",
    "        ep_predicted = []\n",
    "\n",
    "        for i_batch, (data, target) in enumerate(loader):\n",
    "            if isinstance(data, (list, tuple)):\n",
    "                data = map(lambda x: x.to(device=self.device), data)\n",
    "            else:\n",
    "                data = data.to(device=self.device)\n",
    "            target = target.to(device=self.device)\n",
    "            target_o = F.one_hot(target[:, 0].long(), num_classes=2).float()\n",
    "\n",
    "            out = self.model(data)\n",
    "            loss = self.loss_fn(out, target_o)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(out.detach(), dim=1)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            ep_target.append(target[:, 0])\n",
    "            ep_predicted.append(predicted)\n",
    "\n",
    "        train_loss /= len(loader)\n",
    "        \n",
    "        ep_target = torch.cat(ep_target).cpu()\n",
    "        ep_predicted = torch.cat(ep_predicted).cpu()\n",
    "        train_acc = f1_score(ep_target, ep_predicted)\n",
    "        \n",
    "        return train_loss, train_acc\n",
    "\n",
    "    def __valid_epoch(self, loader):\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ep_target = []\n",
    "        ep_predicted = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_batch, (data, target) in enumerate(loader):\n",
    "                if isinstance(data, (list, tuple)):\n",
    "                    data = map(lambda x: x.to(device=self.device), data)\n",
    "                else:\n",
    "                    data = data.to(device=self.device)\n",
    "                target = target.to(device=self.device)\n",
    "                target_o = F.one_hot(target[:, 0].long(), num_classes=2).float()\n",
    "\n",
    "                out = self.model(data)\n",
    "                loss = self.loss_fn(out, target_o)\n",
    "                _, predicted = torch.max(out, dim=1)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                ep_target.append(target[:, 0])\n",
    "                ep_predicted.append(predicted)\n",
    "\n",
    "            valid_loss /= len(loader)\n",
    "            \n",
    "            ep_target = torch.cat(ep_target).cpu()\n",
    "            ep_predicted = torch.cat(ep_predicted).cpu()\n",
    "            valid_acc = f1_score(ep_target, ep_predicted)\n",
    "            \n",
    "        return valid_loss, valid_acc\n",
    "    \n",
    "    def __logging(self, message):\n",
    "        self.logger.log(message)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e563c7d5-631f-41f3-b6a0-52afbdc0361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.features = dataset[:][0][0]\n",
    "        self.static_features = dataset[:][0][1]\n",
    "        self.labels = dataset[:][1]\n",
    "        assert batch_size % 2 == 0\n",
    "        self.batch_size = batch_size\n",
    "        self.n_samples = batch_size // 2\n",
    "        \n",
    "        label_counts = np.bincount(self.labels.view(-1).long())\n",
    "        if label_counts.shape[0] != 2:\n",
    "            raise ValueError(f'Expected 2 class but got {label_counts.shape[0]} class')\n",
    "        if label_counts.min() < self.n_samples:\n",
    "            raise ValueError('`n_samples` must be less than minor label data size')\n",
    "            \n",
    "        major_label = label_counts.argmax()\n",
    "        minor_label = label_counts.argmin()\n",
    "        self.major_indices = np.where(self.labels == major_label)[0]\n",
    "        self.minor_indices = np.where(self.labels == minor_label)[0]\n",
    "        \n",
    "        np.random.shuffle(self.major_indices)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        while count + self.n_samples < len(self.major_indices):\n",
    "            mini_major_indices = self.major_indices[count:count+self.n_samples]\n",
    "            mini_minor_indices = np.random.choice(self.minor_indices, self.n_samples, replace=False)\n",
    "            mini_indices = mini_major_indices.tolist() + mini_minor_indices.tolist()\n",
    "            \n",
    "            features = self.features[mini_indices]\n",
    "            static_features = self.static_features[mini_indices]\n",
    "            labels = self.labels[mini_indices]\n",
    "            yield (features, static_features),labels\n",
    "            \n",
    "            count += self.n_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0c1ac2-2983-4ab5-a12b-d56380519ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, targets): \n",
    "        bce_loss = F.binary_cross_entropy_with_logits(outputs, targets)\n",
    "        logpt = -bce_loss\n",
    "        pt = torch.exp(logpt)\n",
    "        focal_loss = -((1 - pt) ** self.gamma) * logpt\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fab3e372-219a-45e6-807f-802404cf8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config.BATCH_SIZE\n",
    "\n",
    "train_loader = BalancedLoader(dataset_train, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f20561-15bc-4437-b2ad-c5849a05a66b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bb15a1e-0309-42c6-8f9a-24c7eadb4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_tr = torch.load('./datasets/features_train.pkl')\n",
    "X_va = torch.load('./datasets/features_test.pkl')\n",
    "\n",
    "# dataset\n",
    "time_step = 12\n",
    "prediction_horizon = 1\n",
    "space_window = None\n",
    "static_col = None\n",
    "\n",
    "dataset_train = STDataset(X_tr, y_tr, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)\n",
    "\n",
    "dataset_valid = STDataset(X_va, y_va, \n",
    "                          time_step=time_step, \n",
    "                          prediction_horizon=prediction_horizon,\n",
    "                          space_window=space_window, \n",
    "                          static_col=static_col)\n",
    "\n",
    "# loader\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78145076-5255-4a6f-80a4-fc0e7cab6402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 03:45:28.889208 | Time Step: 12 | Loss: 56.652441359661495\n"
     ]
    }
   ],
   "source": [
    "model = HA()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(f'{config.LOG_DIR}/HA.log')\n",
    "\n",
    "val_loss = 0.0\n",
    "for d, t in val_loader:\n",
    "    out = model(d)\n",
    "    loss = loss_fn(out, t)\n",
    "    val_loss += loss.item()\n",
    "    \n",
    "val_loss /= len(val_loader)\n",
    "\n",
    "msg = f'Time Step: {time_step} | Loss: {val_loss}'\n",
    "logger.log(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e034a2e-a655-4452-8193-95b577337d1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c322e5d-ec12-4ce1-be2c-c78628467dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 30\n",
    "hid_dim = 64\n",
    "\n",
    "# path\n",
    "log_path = './logs/LSTM.log'\n",
    "# log_path = None\n",
    "\n",
    "model = LSTM(hid_dim).to(device=device)\n",
    "model_name = 'LSTM'\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed214934-0aab-4ae0-8701-4f692c8f670f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-12 16:43:49.212220 | Epoch: 1 | Train Loss: 84.481, Train Time: 52.79 [sec] | Valid Loss: 26.293, Valid Time: 3.44 [sec]\n",
      "2022-08-12 16:44:45.271707 | Epoch: 2 | Train Loss: 20.682, Train Time: 52.62 [sec] | Valid Loss: 19.820, Valid Time: 3.44 [sec]\n",
      "2022-08-12 16:45:41.675216 | Epoch: 3 | Train Loss: 17.737, Train Time: 52.96 [sec] | Valid Loss: 18.742, Valid Time: 3.44 [sec]\n",
      "2022-08-12 16:46:38.149782 | Epoch: 4 | Train Loss: 17.210, Train Time: 53.03 [sec] | Valid Loss: 17.337, Valid Time: 3.44 [sec]\n",
      "2022-08-12 16:47:33.647089 | Epoch: 5 | Train Loss: 16.956, Train Time: 52.06 [sec] | Valid Loss: 18.391, Valid Time: 3.44 [sec]\n",
      "2022-08-12 16:52:14.797811 | Epoch: 10 | Train Loss: 16.408, Train Time: 52.68 [sec] | Valid Loss: 17.449, Valid Time: 3.43 [sec]\n",
      "2022-08-12 16:56:53.519520 | Epoch: 15 | Train Loss: 16.148, Train Time: 52.87 [sec] | Valid Loss: 17.652, Valid Time: 3.44 [sec]\n",
      "2022-08-12 17:01:33.893669 | Epoch: 20 | Train Loss: 16.012, Train Time: 52.45 [sec] | Valid Loss: 17.840, Valid Time: 3.43 [sec]\n",
      "2022-08-12 17:06:11.600662 | Epoch: 25 | Train Loss: 15.913, Train Time: 51.65 [sec] | Valid Loss: 17.444, Valid Time: 3.44 [sec]\n",
      "2022-08-12 17:10:51.170109 | Epoch: 30 | Train Loss: 15.844, Train Time: 52.61 [sec] | Valid Loss: 16.269, Valid Time: 3.42 [sec]\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b1086e4-af21-4f62-9f76-a8dce73694e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:00:25.199092 | Epoch: 65 | Train Loss: 15.600, Train Time: 52.03 [sec] | Valid Loss: 17.158, Valid Time: 3.43 [sec]\n",
      "2022-08-13 16:05:01.422273 | Epoch: 70 | Train Loss: 15.582, Train Time: 51.30 [sec] | Valid Loss: 17.382, Valid Time: 3.42 [sec]\n"
     ]
    }
   ],
   "source": [
    "extra_epochs = 10\n",
    "\n",
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, extra_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bfb0df9-effc-4d3d-8582-0ff50cf01601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./models/LSTM_{trainer.current_epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966341b2-e7b3-42a3-b1ab-b4f0c2786674",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM + Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900b657-b42a-44fc-9d7b-7299afc3059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 50\n",
    "hid_dim = 64\n",
    "\n",
    "# path\n",
    "# log_path = './logs/mini_LSTM+Embedding.log'\n",
    "log_path = None\n",
    "\n",
    "# model\n",
    "model_name = 'Embedding+LSTM'\n",
    "model = LSTM_Embedding(hid_dim).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ab74d-eb2c-4218-8980-cf59a29cc5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ea05b-7349-48b4-9d0b-97ae231340a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./models/Embedding+LSTM_{trainer.current_epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63958339-c869-45ba-aa05-7efb75ec1502",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conv1d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a533425d-b5de-4912-92ad-9d84b680629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 20\n",
    "hid_dim = 64\n",
    "kernel_size = 5\n",
    "num_layers = 1\n",
    "\n",
    "# path\n",
    "log_path = './logs/Conv1d+LSTM.log'\n",
    "\n",
    "# model\n",
    "model_name = 'Conv1d+LSTM'\n",
    "model = Conv1dLSTM(hid_dim, kernel_size, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4396a77b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:13:24.592070 | Epoch: 1 | Train Loss: 26.649, Train Time: 68.92 [sec] | Valid Loss: 19.661, Valid Time: 4.41 [sec]\n",
      "2022-08-13 16:14:39.701245 | Epoch: 2 | Train Loss: 16.388, Train Time: 70.71 [sec] | Valid Loss: 17.128, Valid Time: 4.40 [sec]\n",
      "2022-08-13 16:15:54.422551 | Epoch: 3 | Train Loss: 15.679, Train Time: 70.32 [sec] | Valid Loss: 16.343, Valid Time: 4.40 [sec]\n",
      "2022-08-13 16:17:08.979779 | Epoch: 4 | Train Loss: 15.335, Train Time: 70.15 [sec] | Valid Loss: 18.859, Valid Time: 4.40 [sec]\n",
      "2022-08-13 16:18:23.644423 | Epoch: 5 | Train Loss: 15.126, Train Time: 70.27 [sec] | Valid Loss: 15.086, Valid Time: 4.40 [sec]\n",
      "2022-08-13 16:24:37.372779 | Epoch: 10 | Train Loss: 14.589, Train Time: 70.28 [sec] | Valid Loss: 14.881, Valid Time: 4.41 [sec]\n",
      "2022-08-13 16:30:46.669056 | Epoch: 15 | Train Loss: 14.322, Train Time: 68.70 [sec] | Valid Loss: 16.136, Valid Time: 4.41 [sec]\n",
      "2022-08-13 16:36:49.950481 | Epoch: 20 | Train Loss: 14.125, Train Time: 68.48 [sec] | Valid Loss: 16.484, Valid Time: 4.41 [sec]\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e15fb416-665a-4d1e-9382-b81b052a09bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 03:53:57.373291 | Epoch: 45 | Train Loss: 13.623, Train Time: 69.93 [sec] | Valid Loss: 16.044, Valid Time: 4.41 [sec]\n",
      "2022-08-14 04:00:11.166217 | Epoch: 50 | Train Loss: 13.556, Train Time: 70.18 [sec] | Valid Loss: 17.094, Valid Time: 4.42 [sec]\n"
     ]
    }
   ],
   "source": [
    "extra_epochs = 10\n",
    "\n",
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, extra_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e78d8435-604f-4be3-91e1-3754bf1cbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./models/Conv1d+LSTM_{trainer.current_epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c297e-d59c-4970-a59b-0f8eaf1a131d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conv2d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bb6ae-7404-4e3c-b0e0-1e6abd100484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 40\n",
    "hid_dim = 64\n",
    "kernel_size = 5\n",
    "num_layers = 1\n",
    "\n",
    "# path\n",
    "# log_path = './logs/Conv2d+LSTM.log'\n",
    "log_path = None\n",
    "\n",
    "# model\n",
    "model_name = 'Conv2d+LSTM'\n",
    "model = Conv2dLSTM(hid_dim, kernel_size).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c60da-bd73-4904-81b3-b89d423d5c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0e123-67ad-41a1-ab89-d32639986f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, 30, log_steps=5, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd601fe1-728d-48c5-87a1-fcbecea70a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./models/Conv2d+LSTM_traffic_{trainer.current_epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32ba5d-0574-4885-8555-1500b56f3bc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding + Conv2d + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3301e107-e3b5-4ffe-9912-3e912e8a15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 50\n",
    "hid_dim = LSTM_DIM\n",
    "kernel_size = 5\n",
    "num_layers = 1\n",
    "\n",
    "# path\n",
    "model_name = 'jam/bn_drop2_balanced_focal_Embedding+Conv2d+LSTM'\n",
    "log_path = f'./logs/{model_name}.log'\n",
    "# log_path = None\n",
    "\n",
    "# model\n",
    "model = Conv2dLSTM_Embedding(hid_dim, kernel_size).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = FocalLoss(gamma=2.0)\n",
    "\n",
    "logger = Logger(fname=log_path)\n",
    "trainer = CTrainer(model, optimizer, loss_fn, device=device, logger=logger, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aec76554-06f5-4f69-a371-287f1a3cec86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:26:59.868241 | Epoch: 1 | Train Loss: 0.004, Train F1: 0.966, Train Time: 62.00 [sec] | Valid Loss: 0.011, Valid F1: 0.182, Valid Time: 4.02 [sec]\n",
      "2022-08-16 08:28:06.167396 | Epoch: 2 | Train Loss: 0.000, Train F1: 0.986, Train Time: 62.21 [sec] | Valid Loss: 0.007, Valid F1: 0.223, Valid Time: 4.07 [sec]\n",
      "2022-08-16 08:29:11.896019 | Epoch: 3 | Train Loss: 0.000, Train F1: 0.990, Train Time: 61.48 [sec] | Valid Loss: 0.006, Valid F1: 0.256, Valid Time: 4.24 [sec]\n",
      "2022-08-16 08:30:18.671336 | Epoch: 4 | Train Loss: 0.000, Train F1: 0.992, Train Time: 62.62 [sec] | Valid Loss: 0.005, Valid F1: 0.260, Valid Time: 4.14 [sec]\n",
      "2022-08-16 08:31:25.519668 | Epoch: 5 | Train Loss: 0.000, Train F1: 0.993, Train Time: 62.64 [sec] | Valid Loss: 0.006, Valid F1: 0.270, Valid Time: 4.20 [sec]\n",
      "2022-08-16 08:32:41.050675 | Epoch: 6 | Train Loss: 0.000, Train F1: 0.994, Train Time: 71.32 [sec] | Valid Loss: 0.004, Valid F1: 0.257, Valid Time: 4.20 [sec]\n",
      "2022-08-16 08:33:56.654845 | Epoch: 7 | Train Loss: 0.000, Train F1: 0.995, Train Time: 71.52 [sec] | Valid Loss: 0.005, Valid F1: 0.271, Valid Time: 4.08 [sec]\n",
      "2022-08-16 08:35:12.865902 | Epoch: 8 | Train Loss: 0.000, Train F1: 0.996, Train Time: 72.01 [sec] | Valid Loss: 0.005, Valid F1: 0.288, Valid Time: 4.19 [sec]\n",
      "2022-08-16 08:36:28.289014 | Epoch: 9 | Train Loss: 0.000, Train F1: 0.997, Train Time: 71.16 [sec] | Valid Loss: 0.005, Valid F1: 0.268, Valid Time: 4.25 [sec]\n",
      "2022-08-16 08:37:44.041251 | Epoch: 10 | Train Loss: 0.000, Train F1: 0.997, Train Time: 71.68 [sec] | Valid Loss: 0.004, Valid F1: 0.276, Valid Time: 4.07 [sec]\n",
      "2022-08-16 08:38:59.966055 | Epoch: 11 | Train Loss: 0.000, Train F1: 0.997, Train Time: 71.72 [sec] | Valid Loss: 0.004, Valid F1: 0.263, Valid Time: 4.21 [sec]\n",
      "2022-08-16 08:40:16.018158 | Epoch: 12 | Train Loss: 0.000, Train F1: 0.998, Train Time: 71.88 [sec] | Valid Loss: 0.005, Valid F1: 0.269, Valid Time: 4.17 [sec]\n",
      "2022-08-16 08:41:32.232892 | Epoch: 13 | Train Loss: 0.000, Train F1: 0.998, Train Time: 72.01 [sec] | Valid Loss: 0.005, Valid F1: 0.251, Valid Time: 4.20 [sec]\n",
      "2022-08-16 08:42:48.447690 | Epoch: 14 | Train Loss: 0.000, Train F1: 0.998, Train Time: 71.91 [sec] | Valid Loss: 0.006, Valid F1: 0.241, Valid Time: 4.30 [sec]\n",
      "2022-08-16 08:44:04.954216 | Epoch: 15 | Train Loss: 0.000, Train F1: 0.998, Train Time: 72.33 [sec] | Valid Loss: 0.004, Valid F1: 0.257, Valid Time: 4.18 [sec]\n",
      "2022-08-16 08:45:21.524567 | Epoch: 16 | Train Loss: 0.000, Train F1: 0.998, Train Time: 72.29 [sec] | Valid Loss: 0.006, Valid F1: 0.259, Valid Time: 4.28 [sec]\n",
      "2022-08-16 08:46:38.211312 | Epoch: 17 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.45 [sec] | Valid Loss: 0.004, Valid F1: 0.256, Valid Time: 4.24 [sec]\n",
      "2022-08-16 08:47:54.610291 | Epoch: 18 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.20 [sec] | Valid Loss: 0.006, Valid F1: 0.231, Valid Time: 4.20 [sec]\n",
      "2022-08-16 08:49:11.129104 | Epoch: 19 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.47 [sec] | Valid Loss: 0.005, Valid F1: 0.247, Valid Time: 4.05 [sec]\n",
      "2022-08-16 08:50:27.789970 | Epoch: 20 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.37 [sec] | Valid Loss: 0.006, Valid F1: 0.251, Valid Time: 4.29 [sec]\n",
      "2022-08-16 08:51:44.198646 | Epoch: 21 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.97 [sec] | Valid Loss: 0.006, Valid F1: 0.227, Valid Time: 4.43 [sec]\n",
      "2022-08-16 08:53:00.250384 | Epoch: 22 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.87 [sec] | Valid Loss: 0.007, Valid F1: 0.211, Valid Time: 4.18 [sec]\n",
      "2022-08-16 08:54:16.389167 | Epoch: 23 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.82 [sec] | Valid Loss: 0.006, Valid F1: 0.232, Valid Time: 4.32 [sec]\n",
      "2022-08-16 08:55:32.408457 | Epoch: 24 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.83 [sec] | Valid Loss: 0.008, Valid F1: 0.224, Valid Time: 4.19 [sec]\n",
      "2022-08-16 08:56:48.436438 | Epoch: 25 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.80 [sec] | Valid Loss: 0.007, Valid F1: 0.233, Valid Time: 4.23 [sec]\n",
      "2022-08-16 08:58:04.516959 | Epoch: 26 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.73 [sec] | Valid Loss: 0.008, Valid F1: 0.223, Valid Time: 4.35 [sec]\n",
      "2022-08-16 08:59:20.613688 | Epoch: 27 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.74 [sec] | Valid Loss: 0.007, Valid F1: 0.222, Valid Time: 4.35 [sec]\n",
      "2022-08-16 09:00:36.167790 | Epoch: 28 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.40 [sec] | Valid Loss: 0.008, Valid F1: 0.225, Valid Time: 4.15 [sec]\n",
      "2022-08-16 09:01:52.653087 | Epoch: 29 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.15 [sec] | Valid Loss: 0.007, Valid F1: 0.225, Valid Time: 4.34 [sec]\n",
      "2022-08-16 09:03:08.541361 | Epoch: 30 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.69 [sec] | Valid Loss: 0.006, Valid F1: 0.245, Valid Time: 4.20 [sec]\n",
      "2022-08-16 09:04:24.471828 | Epoch: 31 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.86 [sec] | Valid Loss: 0.007, Valid F1: 0.208, Valid Time: 4.07 [sec]\n",
      "2022-08-16 09:05:40.676000 | Epoch: 32 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.02 [sec] | Valid Loss: 0.008, Valid F1: 0.207, Valid Time: 4.19 [sec]\n",
      "2022-08-16 09:06:56.723635 | Epoch: 33 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.66 [sec] | Valid Loss: 0.008, Valid F1: 0.213, Valid Time: 4.39 [sec]\n",
      "2022-08-16 09:08:12.504960 | Epoch: 34 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.68 [sec] | Valid Loss: 0.008, Valid F1: 0.205, Valid Time: 4.10 [sec]\n",
      "2022-08-16 09:09:28.986588 | Epoch: 35 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.12 [sec] | Valid Loss: 0.009, Valid F1: 0.207, Valid Time: 4.36 [sec]\n",
      "2022-08-16 09:10:45.289884 | Epoch: 36 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.06 [sec] | Valid Loss: 0.008, Valid F1: 0.229, Valid Time: 4.24 [sec]\n",
      "2022-08-16 09:12:01.199575 | Epoch: 37 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.84 [sec] | Valid Loss: 0.008, Valid F1: 0.225, Valid Time: 4.07 [sec]\n",
      "2022-08-16 09:13:17.390232 | Epoch: 38 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.99 [sec] | Valid Loss: 0.009, Valid F1: 0.227, Valid Time: 4.20 [sec]\n",
      "2022-08-16 09:14:33.908180 | Epoch: 39 | Train Loss: 0.000, Train F1: 0.999, Train Time: 72.17 [sec] | Valid Loss: 0.007, Valid F1: 0.225, Valid Time: 4.34 [sec]\n",
      "2022-08-16 09:15:50.008213 | Epoch: 40 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.91 [sec] | Valid Loss: 0.007, Valid F1: 0.217, Valid Time: 4.19 [sec]\n",
      "2022-08-16 09:17:06.027466 | Epoch: 41 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.78 [sec] | Valid Loss: 0.009, Valid F1: 0.206, Valid Time: 4.23 [sec]\n",
      "2022-08-16 09:18:22.129125 | Epoch: 42 | Train Loss: 0.000, Train F1: 1.000, Train Time: 71.77 [sec] | Valid Loss: 0.007, Valid F1: 0.236, Valid Time: 4.33 [sec]\n",
      "2022-08-16 09:19:38.068270 | Epoch: 43 | Train Loss: 0.000, Train F1: 1.000, Train Time: 71.83 [sec] | Valid Loss: 0.010, Valid F1: 0.206, Valid Time: 4.11 [sec]\n",
      "2022-08-16 09:20:53.957560 | Epoch: 44 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.71 [sec] | Valid Loss: 0.009, Valid F1: 0.194, Valid Time: 4.18 [sec]\n",
      "2022-08-16 09:22:09.921483 | Epoch: 45 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.77 [sec] | Valid Loss: 0.007, Valid F1: 0.213, Valid Time: 4.19 [sec]\n",
      "2022-08-16 09:23:25.626865 | Epoch: 46 | Train Loss: 0.000, Train F1: 1.000, Train Time: 71.67 [sec] | Valid Loss: 0.008, Valid F1: 0.205, Valid Time: 4.04 [sec]\n",
      "2022-08-16 09:24:41.479541 | Epoch: 47 | Train Loss: 0.000, Train F1: 0.999, Train Time: 71.52 [sec] | Valid Loss: 0.008, Valid F1: 0.225, Valid Time: 4.33 [sec]\n",
      "2022-08-16 09:25:58.058098 | Epoch: 48 | Train Loss: 0.000, Train F1: 1.000, Train Time: 72.09 [sec] | Valid Loss: 0.008, Valid F1: 0.221, Valid Time: 4.49 [sec]\n",
      "2022-08-16 09:27:14.277574 | Epoch: 49 | Train Loss: 0.000, Train F1: 1.000, Train Time: 72.12 [sec] | Valid Loss: 0.009, Valid F1: 0.180, Valid Time: 4.10 [sec]\n",
      "2022-08-16 09:28:30.746152 | Epoch: 50 | Train Loss: 0.000, Train F1: 1.000, Train Time: 72.26 [sec] | Valid Loss: 0.009, Valid F1: 0.200, Valid Time: 4.20 [sec]\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cded3-39d6-40b0-b316-30a2b017a4a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 17:23:03.000391 | Epoch: 21 | Train Loss: 0.012, Train F1: 0.722, Train Time: 29.47 [sec] | Valid Loss: 0.039, Valid F1: 0.168, Valid Time: 4.26 [sec]\n",
      "2022-08-14 17:23:36.853433 | Epoch: 22 | Train Loss: 0.012, Train F1: 0.732, Train Time: 29.51 [sec] | Valid Loss: 0.038, Valid F1: 0.256, Valid Time: 4.33 [sec]\n",
      "2022-08-14 17:24:10.281479 | Epoch: 23 | Train Loss: 0.011, Train F1: 0.739, Train Time: 29.11 [sec] | Valid Loss: 0.042, Valid F1: 0.217, Valid Time: 4.31 [sec]\n",
      "2022-08-14 17:24:44.096840 | Epoch: 24 | Train Loss: 0.011, Train F1: 0.753, Train Time: 29.49 [sec] | Valid Loss: 0.043, Valid F1: 0.237, Valid Time: 4.32 [sec]\n",
      "2022-08-14 17:25:17.973425 | Epoch: 25 | Train Loss: 0.010, Train F1: 0.765, Train Time: 29.54 [sec] | Valid Loss: 0.041, Valid F1: 0.225, Valid Time: 4.34 [sec]\n",
      "2022-08-14 17:25:51.438863 | Epoch: 26 | Train Loss: 0.010, Train F1: 0.776, Train Time: 29.23 [sec] | Valid Loss: 0.043, Valid F1: 0.170, Valid Time: 4.23 [sec]\n",
      "2022-08-14 17:26:25.099145 | Epoch: 27 | Train Loss: 0.009, Train F1: 0.784, Train Time: 29.43 [sec] | Valid Loss: 0.046, Valid F1: 0.233, Valid Time: 4.23 [sec]\n",
      "2022-08-14 17:26:58.745359 | Epoch: 28 | Train Loss: 0.009, Train F1: 0.800, Train Time: 29.42 [sec] | Valid Loss: 0.043, Valid F1: 0.241, Valid Time: 4.22 [sec]\n",
      "2022-08-14 17:27:31.745946 | Epoch: 29 | Train Loss: 0.008, Train F1: 0.806, Train Time: 28.79 [sec] | Valid Loss: 0.047, Valid F1: 0.232, Valid Time: 4.21 [sec]\n",
      "2022-08-14 17:28:05.378846 | Epoch: 30 | Train Loss: 0.008, Train F1: 0.814, Train Time: 29.42 [sec] | Valid Loss: 0.050, Valid F1: 0.215, Valid Time: 4.22 [sec]\n",
      "2022-08-14 17:28:39.151569 | Epoch: 31 | Train Loss: 0.008, Train F1: 0.823, Train Time: 29.44 [sec] | Valid Loss: 0.048, Valid F1: 0.233, Valid Time: 4.33 [sec]\n",
      "2022-08-14 17:29:12.532446 | Epoch: 32 | Train Loss: 0.007, Train F1: 0.834, Train Time: 29.06 [sec] | Valid Loss: 0.050, Valid F1: 0.234, Valid Time: 4.32 [sec]\n",
      "2022-08-14 17:29:45.326252 | Epoch: 33 | Train Loss: 0.007, Train F1: 0.841, Train Time: 28.47 [sec] | Valid Loss: 0.052, Valid F1: 0.223, Valid Time: 4.32 [sec]\n",
      "2022-08-14 17:30:18.913828 | Epoch: 34 | Train Loss: 0.007, Train F1: 0.845, Train Time: 29.27 [sec] | Valid Loss: 0.054, Valid F1: 0.211, Valid Time: 4.31 [sec]\n",
      "2022-08-14 17:30:52.478786 | Epoch: 35 | Train Loss: 0.006, Train F1: 0.856, Train Time: 29.25 [sec] | Valid Loss: 0.055, Valid F1: 0.229, Valid Time: 4.32 [sec]\n",
      "2022-08-14 17:31:24.666791 | Epoch: 36 | Train Loss: 0.006, Train F1: 0.867, Train Time: 27.89 [sec] | Valid Loss: 0.058, Valid F1: 0.219, Valid Time: 4.30 [sec]\n",
      "2022-08-14 17:31:58.083600 | Epoch: 37 | Train Loss: 0.006, Train F1: 0.872, Train Time: 29.11 [sec] | Valid Loss: 0.060, Valid F1: 0.197, Valid Time: 4.31 [sec]\n"
     ]
    }
   ],
   "source": [
    "extra_epochs = 20\n",
    "\n",
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, extra_epochs, log_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95806d53-47b4-4009-b34f-c4706e0fb947",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 学習曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afb674a8-cb27-4040-ae77-1b140045fe1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(range(len(trainer.train_losses)), trainer.train_losses)\n",
    "ax.plot(range(len(trainer.val_losses)), trainer.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5b4a332-4ec9-44f8-bf34-ef879b124eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEvCAYAAAAU8oWdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiQUlEQVR4nO3deXhdVb3/8fc3SdPS0gKFFlqwtAxWQBEkioIKRUQQZFQQBxwYRO9FccDpXry/q4jDVa5eHLCCgog44ATIqCAiFKQVZJCZFiyFDrSlc9Mk6/fHOmlO0jZN2wwrzfv1POc5J2fvs/fKys757LX32mtHSglJkkpV09cFkCSpMwaVJKloBpUkqWgGlSSpaAaVJKloBpUkqWh1vb3C7bbbLo0fP763VytJKti0adPmpZRGrW1arwfV+PHjmTp1am+vVpJUsIh4el3TPPQnSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqWpeCKiLOiYjnIuLstUzbJSLuiogHI+LUbi+hJGlA6+p1VDcAE9cx7X+B84BbgXsj4uqU0tzuKJwkSV1qUaWUHgBmdnw/ImqAw4E/p5SWAjcBb+7WEkqSBrRNHZliW2BOSmlJ5edngbGbuEwNACklWhI0tbTQ0gItKVUebdNWP9O1u1AH0fa68rIlJZpbEk3N+bm56ueOy+34+ZoIamsgIvLriPx+TdDSkmhqSTS3tNBUtfymlkQEBPnzNZXPtC4vJdqVo7V8LS25NBFQG0FtTRCV59b1trT7DO0+31rmIFavn8o6c31X1WNi9W/e+n5rfafK9JYu3Pm7dX2VyiPIdRVV87StJ7V/r7LelFrL0H4eKstq+9usubxUKT+V5VTrrPTV5ataxeplpKrXa/18h8+0q7/E6u244zpbP7f6uVKS6uW1rWMtb9KhHleXd83fv3pbaF1e0FbPq8vdkt9rqfrlW7eT1r9Lq5qqZbZu1zURDK6r4YhXjFlrebtLdwyhVN0qGw680HGGiDgDOANg3Lhx3bDK/iGlxMqmFpaubKKxuYXGpvxY2dTCqtafK88rVrWwsqmZlU0trFxVeW7KX4KtG3n1l1BE3pBaP7+yalkrm1porCxrxarW58ryK88AtTVBXU1N5TmoqTxH5C/i1vCo/udrSakyrX24tL7f+iW0ug6q6qKlw5e0pP5v5LD64oPqBWC7iBieUlpMPo91VceZUkqTgckADQ0NRX9DpZRYvLKJRctX8WLlsWh5/nnxyiaWNzaxrLGZZY3NLG9sZtmqynNjE0sbm1m6sqnt0djc41/IEVBfW0N9XQ2D62pWv66vq2HIoFqG1NWy5eA6th1Wy+BBNQypy88Bq1sAzVWtg+aWvLdeW8PqvfrcMqjsRZFbFLUR1FRaG7WV6RGxxt5iaxkhL68m2kKxNoK62rblt62P1evpuIe+Lu1qubJ3mGD1+mqrHjmc2++1rrFHnjqGcVrd8kuJ1aFeW/1c+V1al9e6x9qyeu8/Veohr7+mqsVUU5N/z+p1traYWpfROn91/be2vlp/31TVMmp9TdXfpO3v0/b710Tr36hqb5m17+lX11dnrZv2n12z5VDd+uq497+2dVWWvMZ87XbgOnx+bVtOdSt69XKryhtrqau1laW6PNXbfs3q7bft89Wt2epWW/65Q0uTNbfFjtb2N6z+e1W3UNf8u7Tt7Fa3itott+p/rrV+W1ttrdv/6tfQpf/PTbVRQRURnwKeTSldGRHXAQdHxC3AvsCHurOA3WFVcwtPv7CMJ+YsZvq8ZSxY1rg6iBatyEHU9nrVGs32jupqgi3qaxlaX8vQ+jq2GJRfb73FIHbcegjD6usYNriOYYNrGTa4jqGDahk8qLZdiFS/HlxXw+C62vxcFSb1tTXU1dZUNdU7bnwwqDbWeZhAkjYH6w2qiBgLXAfsADRHxNuAf9K2A/AJ4GfAV4DzUkrzeqisXbK8sZmbH57N47MX8/jsJTwxdwkz5i2lqSp9hgyqYcSQQWy1xSBGbDGI7basZ5dRw1a/l9+vWz299b3hgwexRX0t9XW9e/lZdUuld/ZfJKkc6w2qlNIsYJ9Opk8HXteNZdpoz7+4glMvu4eHZi2itibYeeRQdhu9JYftuT27jd6S3UZvya6jtmTY4F6/u4kkaSNtNt/YD8x8kdN+cg9LVzZz0Xv2Y9LLRjG4rraviyVJ2kSbRVDd8ODzfPwX9zFyWD1Xffg1vGyHEX1dJElSN+nXQZVS4qLbnuJrNzzCPi/Zmh+e0sCo4YP7uliSpG7Ub4OqsamF//jtA/xq2kyO2nsM33jHKxkyyEN9krS56ZdBtWBpI2f+dBp3T5/PR9+0O2e/aXdqauwNJ0mbo34ZVGddeS/3PrOQb520D8fuu2NfF0eS1IP6ZVD951F7sGRFEw3jR/Z1USRJPaxfBpW9+iRp4PAOv5KkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSiGVSSpKIZVJKkohlUkqSidSmoIuL0iHgwIqZExIQO08ZExF8jYkZE/CQianumqJKkgWi9QRURo4HPAvsDXwIu6DDLx4AbgV2BWuBN3VxGSdIA1pUW1WHAtJTSUnIgHRAR1Z9bBMxIKTUD9wKN3V9MSdJAVdeFecYAjwKklJojYiEwEphXmf594JqIGA5MBL7V/cWUJA1UXe1MUT3fcCBV/XwEcBMwGGgAXtLxwxFxRkRMjYipc+fO3diySpIGoK60qGaRz08RESOAbYAFVdPPAfZPKTVWWltnAp+pXkBKaTIwGaChoaE65CRJ6lRXWlQ3AftGxDDgYOB64KSI+GRl+ghgv4gIYHdgi54oqCRpYFpviyqlNDcizgfuBhYD7wKOB8ZXZnk/ubU0FHgCOKUnCipJGpgipd49EtfQ0JCmTp3aq+uUJJUtIqallBrWNs2RKSRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUUzqCRJRTOoJElFM6gkSUXrUlBFxOkR8WBETImICR2m1UfERRHxQETcGhE79UxRJUkDUd36ZoiI0cBngb2Bg4ALgOOqZvk3YFVl+m7AnO4vpiRpoOpKi+owYFpKaSlwI3BARFR/7j3ABSl7PKXU2BMFlSQNTF0JqjHAowAppWZgITCyavpOwJER8feIuDgi1ttKkySpq7ramaJ6vuFAqvp5GDALaAB2AI7p+OGIOCMipkbE1Llz525sWSVJA1BXgmoWMBEgIkYA2wALqqY/B9yTUmoBbiWfp2onpTQ5pdSQUmoYNWrUppdakjRgdCWobgL2jYhhwMHA9cBJEfHJyvTfAydUDvkdDDzYA+WUJA1Q6w2qlNJc4HzgbuBzwCeBscD4yiznAYcADwMzget6oqCSpIGpSx0fUkqXAJdUvfXNqmkLgaO7t1iSJGWOTCFJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSpal4IqIk6PiAcjYkpETFjHPJ+NiBndWjpJ0oC33qCKiNHAZ4H9gS8BF6xlnh2BI7u9dJKkAa8rLarDgGkppaXAjcABEdHxc1+rPCRJ6lZdCaoxwKMAKaVmYCEwsnViRBwIDEspXdsTBZQkDWx1XZyvOtCGAwkgImqBrwLv6ezDEXEGcAbAuHHjNryUkqQBqystqlnARICIGAFsAyyoTHsVMBb4RUTcBYyJiF90XEBKaXJKqSGl1DBq1KjuKbkkaUDoSovqJuCLETEMOBi4HjgpIsamlL4J7No6Y0TMSCmd1CMllSQNSOsNqpTS3Ig4H7gbWAy8CzgeGN+zRZMkqYvnqFJKlwCXVL31zXXMN74byiRJ0mqOTCFJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppBJUkqmkElSSqaQSVJKppB1ZeevhO+8xq4+ixoWtnXpZGkIhlUfaGpEf70Rbj0SFi+AP7+E/jJMbB0Xl+XTJKKY1D1trmPwSVvhtu/Cfu8Gz76dzjhEph1L/xwEsz+Z1+XUJKKYlD1lpTgbz+EH7wRFj4DJ/0UjvkODB4Or3g7vP+6fPjvksPgsZu6trxVK3q+3JLUxwyq3rB4NlzxDrjuU7DzAfCRKbDH29rPs9N+cPqtMHICXHkSTPluDqNqq5bDYzfCNR+DC/aAr+wE130alszpvd9FknpZXV8XoN9Y8DSklhwkXZUS3P9LuPFz0LgUjvgfeM3pELH2+bfaET54A/z2Q3Dj52HuI/DGT8OTt8BjN8CTt0LTcqjfEnY9JLfG7rkY7v0pvO4jcMBZMGSr9Zdr2XwYsjXUuJ8iqXyROu6197CGhoY0derUXl3nRmtugsdvhHsugSf/BAS88mSY9HnY+iWdf/aFJ+Haj8P022DHBjjmuzD6ZV1bb0sL3PpluP0bbe9tNQ4mHg4vPRzGvx7qBuf35z0Bt54HD/0WttgGXv9xeM0ZMGiLts8ufQFm3A7T/5LL88ITMHbffG5s2103qEokqSdExLSUUsNapxlUa7H4+dwTb9qlsOhZGD4W9ntfbhXd/YM8z/5nwOs/AUNHtv9s00r467dyZ4m6IXDoF2C/D0BN7YaX49EbYO7DsNubYfu91t0SA5h1H9zyJXjijzB8DLz2I7Bkdg6m5x/I89RvCTsfCGP2zufLWprhbd/K58gkqQ8ZVOvT1Jg7OMx7DO7/BTxyLbQ0wS6T4NWnwkuPgNrKUdKF/4Jbz4d/XAlDRuSw2v9DuQUz/fbcinrhcdjreDj8KzB8h979XWb8Ff743zDzb1BbDy/ZHyYcBLsclFtRtYPafo9fnwb/ugv2eQ+89etQP6z7y9O4DBY/l8+jDRkBW+8Mg7fs/vVI6tcMqlYp5fM9zz8AC6bD/Kdg/gxYNDOff4J8+Gyfd0PDBzs/LPb8g/Cn/4bHb4IRO8KO+8HDV+cv4iMvgN0P7ZVfaa1SgnmP58OT1YcAO2pugtu+Cn/5Bmy3O7z9x7DDyzdunUvnwd8mw4IZuUXa+lj54przDt0219M2O7c973IwjNxl49Ytqd8zqFrdczH84ZP59dBtYZsJ+ctx5ITK6wkw5pWdf7l3NP12uPkL8Pz9cMBH4Y3nQP3Qnil/T3nqNvjNGfni47d8GV59WueHGTt6+Bq45mxYPh9G7JRbkcN3yIcgW5+3HAUrFsHCp3OYLXg6v174L2hZBYO3gvdfk+tf0oBjUEFuAf3wEJjwhtxyGDKi+5adUj5U2HpYrT9aMhd+92F44uZ8yPP1Z+dDhp0F1vIFcP1n8uHSHfaG4y7K59I2REtzPuR6xTtg1TL4wPUwauLG/Q4rl+SeknP+mS+cnv8U7HMy7HXcxi1PUq8xqBqXwuRJsGIhnHlH3rvXmlpa8uG7278BS+fC9i/PnTJe8fa2XoatHr85j1G4ZE5uRb7xU5sW1C88CT8+AqImd9HfZvz6P7Nsfu7c8vz9MPuh3EJrNWho7oK/5Hk47gew94kbXzZJPc6guvos+PvlcMrv8rkQdW7VCnjwKpjyPZjzEAwbnQ8HvvrU3EHjxs/DvZfDqD3guO/nThrdYfY/4dK3wuAROaxGjF33vA9fmzuuLJsH2+4O2+8Jo/eC0Xvk11uPh6YV8LMT4ek74LjJsPc7uqecm4OU4I5vwzN3wTt+vGGHu6UeMLCD6sFfw1UfzL3zDv2v3lvv5iAleOrPcNf3cqeR2sGwxda5tXXAR/P1ZB1bWpvq2Wlw2TEwYkw+DDhsu/bTl82H6z8ND/wKdngFHPv9/LwujUvhihPhmTvh+B/aFR9yT8yr/z3/bwAc+DF48xf7tkwa8AZuUC2YARe9IZ/z+MD1/fscUl+b+yjc9X2Y/yQcci685DU9t64Zd8BPT8g9Ed93TQ5HaGtFLZ+fR+x4wye69jdtXJrPgT0zBU64GF5+Qs+VvXSLZsGVJ8Nz/8g7bi88CfddAaf9MfdcVfdIKV9TOWhIX5ek3xiYQdW8Cn50eO6mfebtuQu0+o/H/whXvhN2fFUeQeNP/931VtTarFySw+pfd8PbL+n9DhYpwcx7IGrz77QhvSq7y8yp8PN35eA+4WKYeASseBG++9o89NaHbuv+FvJAlBL8+tQ8EsypN2/YsGsDWGdBtfkO9nbrl+HZqXD0tw2p/mj3Q3OgzLwHvr13HiLq4M/lgXs3NKQgX2T87l/lluBVp8I/f79x5ZpxB1x6VB4MePpf8rVonVkyJ49U8p2GfHuXiw/JvU8fuCrvTPWWf/wCfvzWfC7qtD/mkIIcUEf9bx4B5fZv9l55NkZzU+7wU7q/fCMfVl2+EH7+7rxjoE2yebaonrwVLj8uD3v0tm/37LrUsx64Cu77GRz6//LQT5tq5eJ8WPHZaXD85A07DHj/r+D3H4EtRuYepE0r8uuJR8DLjoJdJ+UgaGmGJ/4Ef78sDybc0gTjXgf7vjd3wW89hDpixzwu437vyxea94SW5twavePbMP4N8I7LYNi2a873mzPyl+sZf964HYGe9tSf4Zfvy3U5amLuNDNqj/w8eo98rV5rK7VpZQ6J5Qvy32n5AmhuzHW8xch8DeXQkT3TenzkD7nVuvdJ+XHF22GPo+Edl/ZNK7ofGViH/pbMhYsOzBvk6bf0v4tv1fNWLKocBrwrj0Jy+Fc6H3U+pdxl/5bzYOfXwzt/mns/PvGnPNzWYzfkQ2iDhsKEN8Jz98PiWTB0u3wd176nwKiXti2vpSV3Trnru7lVNmgY7POu/Bi2XR6TsX5YXkf1l1tzU+6CP/+pfG7phSdy4M2fnr+c16a5MfeMbPggHPH1dZ/TWzYfvrt/vkD79FvKOp/74G/yHQVG7pqvg5zzcL5ebunctnmGbAX1w3MorepiC2bQsBxaw7eH3Q6FPY+BUS/b+ECZ8zBcfGg+t/qB6/NOyx3/BzefC2/6Arzhkxu33O7w6PVw+wWw5WjY7qX5Meqlucdsd15TugkGVlD95gx46Hd5z3D7PXtuPerfmhrhL1/P/7zDx+SbWO46ac35mlflDhz3Xp73kI++cM098eZVeXT6h6/No+xvuzu86pQ80n1dfefleP6B3MJ64Fc5VKrV1OXAqt8yD2q8aFZuUbQaPKIyssounYzTmHK47nPyequEf14Nv3xv33+pVvvbD+G6c2Dca+HkK9u3PJfOawutOQ/n+7UNHZk73wzZutKCqjxqB+UQWzY/d8ZZ9gIsW5Bfz38K/vU3IOUv8D2PzaG1voGgqy2bnw/pNi7N3z1b7ZjfTymPqfngr+Fdv4CXvqVbq2e9UoI7vpXH/xw5IW9T859qvx0NH5NbpYd9uU+/MwdOUD1zN/zoMHjDp+BN5/bMOrR5mTkNfndmHh2j4dTcTbt10NwVi+CXp8BTt+aLmif9R88dvlk8O3ehb1xaeSxp/7ppJWz1kjz+5Mhd8/OwUd1fnl++Dx69Ds7868aPENIdUsrnmf/yPzDxrfD2H/XstV6LZ+exOv/5+3zdXWrJ9bznMbDvezof97O5Ca44AZ6+E97/hzV7xDYugx+9JfdCPv2W3OLqDatWwDUfzSPH7HV8vtVQ/dC8Y7VgRu7JO++x3OHssRtg63G5fBtzp4duMDCCqqU579EsmQNnTe2ZkcC1eVq1PB/Wm/Ld3PHm2O/nf9orToR5j8JR34JXvbevS9k7lszJhwC33RU+eOOGf2k1Lssj9w8aBjs1bFyQNjfBHz6Rz/Ht+95c/613L+gNS+bCI9fk0Jp+ew6tiUfAaz+cz/N1/J1u+Hw+jHv0d9a9nSx8BiYfnA81nvanjT/ctuDpfG50fTsRi2fnc2XPToVJ/5lHjunsb/HAVbmn4tv+L58z7QMDI6imXZb3Hk64xIs6tXFm3JHHO1z4TD581NIMJ16W76Y8kNz/K/jNafCW8+F1/9b5vE2NuWPK9L/kx8y/tR3C3GZCvtHo3id2vYv2qhX5C/ORa/Phx0PO7dtOCIufzzdOnXpJPly4/StyYLUOK3bfz/I2s/+ZcMTXOl/WjL/CZUfD7ofBO3+24XfYnnYZXPepXL+j9sgdgV5+/JqtvVn35ZBaviAPH7bn0etfdkp5CLN5j8NZ09quXexFmxxUEXE68DFgMfCulNL0qmnHAJ8BtgUuTymd19myeiSoli+EC/drO4lp7xptrJVL8mj4rRcHb+ggu5uDlPJFwU/eknsA1g9t6+DRes6stj5fNPzMlNyTkcgj3094Y34snZvv2Tb9diDlXo97n5SvX2v9Ekwpf5kumpUfi2fBP36el3n41+C1Z/ZhJXSwajnc/8t8PnHuw/mw6ytOzHdkGLc/vOc3XeuAcvdkuP4cOOgzeWSXrmhamUdjmXZpHjB64hH5co1npuTpY/bJobXXcbkF9dsP55bbyVduWE/Z5+6HyQfl0D38K13/XDfZpKCKiNHAFGBv4CDg9JTScZVpAXwauBBIwKPAm1NKj65reT0SVDd8Lm9AH7rN20RI3WHx7NytffHza543W7UsP4+aWAmmg2D8gWvvYv/izPwF/4+f58OotYPzl+fSefmGmk0r2s8/aGjusFLqUZGU8jnLu76fe25uvXPuPNHxTt+dff73/w73/RR2f0sOrJ06GRFk0ax8nnTmPfD6j+cWZuvh2Bdn5o5jD/4aZv297TM7vQbeeUXu4behrjk73938w3fC6Jdt+Oc3waYG1XuAo1NKJ0ZELTALGJNS650G2837O+A7KaU/rmt53R5Ucx7J3dH3fW++rbqknpfShh25SAlm3ZsDa/ZDuUv4iLEwfGwe13HEjm33Lyupa3xn5j+Vu8Rv6N0Ymhrhzv+DKd/JLcrdDs2B1bETxtN35s4tjUvh2O/BXsd2XpaHfpsPVx/4sY2/RmzpC3Dhvnmg6ff+bv1/45VLcqeMzsK2izY1qM4BRqSUzq38/ChwYEppXof5BpFbVK9LKc3uMO0M4AyAcePG7ff000/TLVKCy4/N/wBn3bv2CxklqUQrF+dDh3demM9/7XJwDqxxr8vd8m/8XG6xvfOK3H28t7QenjzpCtjjqHXPN396Hnlj8Sz42P2bfD1WdwyhVD3fcPJhvo7OBG7pGFIAKaXJKaWGlFLDqFHdeC+oR/6Qr1if9B+GlKT+ZfDwfDjv7AfgsPPybW5+fEQ+3379ObmldfotvRtSkC8OH71nDspVy9c+z1O3wQ8nwaJn86UDPXzRcFeCahYwESAiRgDbAAuqZ4iItwDvBz7ezeVbt1Ur8n2RRu2Rr3+RpP6ofhgccBacfX/uRBI1cPDn4Z1X9knvO2rr4PCv5t6vd36n/bSU4K6L8hB1W26fg7QXesV25eKEm4AvRsQw4GDgeuCkiBibUvpmRLwa+B5wSEppcc8VtYMpF+bhZE75fe9eYyFJPWHQFrmnYwm9HXc5KF/s/NcL8qgmW+2Uex9e+4ncEWTikXD8D3KrsBest0WVUpoLnA/cDXwO+CQwFhhfmeU6YBDwm4i4LyK+0TNFrfLis3nomz3e5h17JaknHHZevtj55i/k3p+XHplD6qDPwEk/7bWQgq61qEgpXQJcUvXWN6umdeNJpy66+Qu5Ag/7cq+vWpIGhK3HwYFnw21fzX0BVq2AE3+SW1q9rH8eM9vnZNj5dd5nSpJ60oEfyxduk+CUq2GHl/dJMfpnUO12aF+XQJI2f/VD8x3Sa+t7dlDg9eifQSVJ6h2d3autl2y+t6KXJG0WDCpJUtEMKklS0QwqSVLRDCpJUtEMKklS0QwqSVLRDCpJUtEMKklS0QwqSVLR1nsr+m5fYcRcoDvuRb8dMK8blrM5s446Z/10zvpZP+uocxtSPzuv624cvR5U3SUipqaUGvq6HCWzjjpn/XTO+lk/66hz3VU/HvqTJBXNoJIkFa0/B9Xkvi5AP2Addc766Zz1s37WUee6pX767TkqSdLA0J9bVJKkAaBfBlVEnB4RD0bElIiY0NflKUVEnBMRz0XE2ZWft4uIP0bEQxFxbh8Xr09FxPCIuDwi7qtsN7tGxBYRcVWlfr4bEbV9Xc6+EhETIuLayv/V1IjYw+1n7SJiq4iYHRHvdxtqLyKaKv9j90XEhd1VP/0uqCJiNPBZYH/gS8AFfVuiotwA/KHq53OB3wF7A0dGxCv7olCFeDlwRUppH+AK8rZzJjAjpbQXMAo4qu+K1+dWAB9PKb0cuAw4B7efdfkv4LnKa7eh9v6VUtqn8jiLbqqffhdUwGHAtJTSUuBG4ICI6I+/R7dLKT0AzKx660jglpRSM3BV5ecBKaU0JaV0Q+XHvwLjqNRP5b1fMrDr57mU0uOVHcGXAtNw+1lDROxB3km+uvKW21B78zv83C310x+/4McAjwJU/oEWAiP7skAFGwU8WXn9LDC2D8tSkv2Bv1O1LWH9EBEHAbPIQXURbj/tRESQj+B8FGipvO021N7YiLijcnj9ALqpfvpjUEH7cg8H7Lq4dlF5gPUEQESMAD4BfLvyVuu2NODrJ6V0GzAUuBP4Om4/HR0DPJFSmtbhfbehNkcDhwAXApdX3tvk+umPQTULmAirv3S2ARb0aYnKNRvYrfJ6IrnuBqyIGAz8Gjg/pfQkVdsS1g8AKaVGcogfi9tPRycBr4+Iu4DTyOfw9sRtaLWU0j0ppZXAz4FtgTl0Q/30x6C6Cdg3IoYBBwPXp5RaOv/IgHUtMKnS0+Yg2ne0GFAq5zEvJZ/fvKzy9rXApMrrSQzs+jk9Il5WObz1dvLA0W4/VVJKJ6eU9k0pvRa4mNwh52zchgCIiEMiYnzlx0nADHJnnE2un7pNLFuvSynNjYjzgbuBxcC7+rhIRYiIscB1wA5Ac0S8DTiRvGdzJnBlSun+PixiX/sw8E7g7oi4r/Lee4FzI+Ih4M/kL+aB6m7ge+RzCC8C7yfvDbv9dG4ycJnbEJC3l8kRsSOwEngf8BjdUD+OTCFJKlp/PPQnSRpADCpJUtEMKklS0QwqSVLRDCpJUtEMKklS0QwqSVLRDCpJUtH+P4ltzmX9OQgbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(range(len(trainer.train_accs)), trainer.train_accs)\n",
    "ax.plot(range(len(trainer.val_accs)), trainer.val_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313512b5-4c4d-48aa-ba0f-63c3d3e74035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.validate(train_loader))\n",
    "print(trainer.validate(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849861c-36f1-4999-8a66-566bac30fc34",
   "metadata": {},
   "source": [
    "## 予測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb058e7-c2b5-4f58-97c9-cd0639102317",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2022/5/1') - dt.timedelta(minutes=15) * time_step\n",
    "end_date = pd.Timestamp('2022/5/9') - dt.timedelta(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa995b0-32cd-4ee1-b6af-fe3de2fd3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sec_table.shape[0]\n",
    "T = int((end_date - start_date).total_seconds() // (60 * 15))\n",
    "D = len(feature_col)\n",
    "\n",
    "X_test = torch.empty((S, T, D), dtype=torch.float32)\n",
    "y_test = torch.empty((S, T, 1), dtype=torch.float32)\n",
    "\n",
    "for sec_id, (s_name, e_name, *_) in sec_table.iterrows():\n",
    "    query = f'start_name == \"{s_name}\" & end_name == \"{e_name}\"'\n",
    "    df_sec = df_all.query(f'start_name == \"{s_name}\" & end_name == \"{e_name}\"')\n",
    "    df_sec = df_sec[(df_sec['datetime'] >= start_date) & (df_sec['datetime'] < end_date)]\n",
    "    \n",
    "    data = df_sec.loc[:, feature_col].values\n",
    "    target = df_sec.loc[:, target_col].values\n",
    "    \n",
    "    X_test[sec_id] = torch.from_numpy(data)\n",
    "    y_test[sec_id, :, 0] = torch.from_numpy(target)\n",
    "    \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "dataset_test = STDataset(X_test, y_test, time_step=time_step, prediction_horizon=prediction_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea87be-7c0d-4929-9726-a313eceb9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_test[:][0].to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(data)\n",
    "\n",
    "pred = pred.view(S, -1).to(device='cpu')\n",
    "target = dataset_test[:][1].view(S, -1).to(device='cpu')\n",
    "\n",
    "plot_sections = [27, 36]\n",
    "fig, axes = plt.subplots(len(plot_sections), 1, figsize=(15, 7))\n",
    "for i, sec_id in enumerate(plot_sections):\n",
    "    axes[i].plot(target[sec_id], label='true')    \n",
    "    axes[i].plot(pred[sec_id], label='pred')\n",
    "    \n",
    "    title = f'{sec_table.loc[sec_id, \"start_name\"]} ~ {sec_table.loc[sec_id, \"end_name\"]}'\n",
    "    axes[i].set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe87e3f-1a43-4d7e-baf0-c1d0827e346d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5a7dd-2786-4b7f-8db8-1b8fd9747d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70220b82-63db-44ff-94e5-670621ccdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = df_test[(df_test['start_name'] == '鶴ヶ島') & (df_test['direction'] == 1)]\n",
    "tmp_train = tmp_train.loc[:, key_col + features]\n",
    "\n",
    "# 時系列長\n",
    "N_period = tmp_train.drop_duplicates(\"datetime\").shape[0]\n",
    "# 区間数\n",
    "N_sec = tmp_train.drop_duplicates([\"start_name\", \"end_name\"]).shape[0]\n",
    "# 特徴量数\n",
    "D = len(features)\n",
    "\n",
    "tmp_train_value = tmp_train[features].values.reshape(1, N_period, D)\n",
    "tmp_train_norm = (tmp_train_value - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c00c2-90d7-4da0-963f-7f631e0a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X = []\n",
    "\n",
    "for i in range(N_sec):\n",
    "    for t in range(time_step, N_period - 24):\n",
    "        time_pred = t + 24\n",
    "        time_input = (t - time_step, t + time_step + 1)\n",
    "        x_ = tmp_train_norm[i, time_input[0] : time_input[1]]\n",
    "        tmp_X.append(x_)\n",
    "\n",
    "tmp_X = torch.from_numpy(np.array(tmp_X, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1369b62-c2ce-4512-a50c-e050ade2ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model(tmp_X.to(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a600e-c0c8-4e35-ab44-0070998eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.arange(time_step, N_period - 24) + 24\n",
    "tmp_y = tmp_train.iloc[ys, -1].values.reshape(-1, 1)\n",
    "tmp_y = torch.from_numpy(tmp_y).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7908b-8ca8-45f2-ab77-9f9571a38319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7632f-df57-4347-a9e6-bf336e0cfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122439-cf23-4510-9a91-ab1dfab22159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for data, target in dataset_train:\n",
    "        if i >= 10:\n",
    "            break\n",
    "        i += 1\n",
    "        print(f'------- {i} -------')\n",
    "        out = model(data.to(device=device))\n",
    "        print(target)\n",
    "        print(out)\n",
    "        print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cdb92-cd84-4abb-97f8-65ea5a5f3cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 3000\n",
    "in_dim = X_train.shape[-1]\n",
    "hid_dim = 100\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device=device)\n",
    "        target = target.unsqueeze(1).to(device=device)\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch < 3 or (epoch + 1) % 100 == 0:\n",
    "        print(f'{dt.datetime.now()} | Epoch {epoch+1} | Loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
