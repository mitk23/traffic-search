{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f9b686-4dee-4846-b006-9d3b39292662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from trainer import Trainer\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a66af52-fa9b-44a1-8e3d-7c1ab733e773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529b47c5-ece1-4061-b622-f0c26c9de6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 道路名\n",
    "# TARGET_ROAD='tateyama'\n",
    "TARGET_ROAD='kannetsu'\n",
    "\n",
    "# 交通量\n",
    "PROCESSED_DATA_DIR = '../Input_processed_data'\n",
    "TRAFFIC_DIR = f'{PROCESSED_DATA_DIR}/traffic'\n",
    "TRAFFIC_CSV = f'{TRAFFIC_DIR}/{TARGET_ROAD}_20220621all-merged_filled_15min.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f0112-9df1-4430-a141-c4b94a5a4962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 前処理してデータセットを作成\n",
    "- 渋滞量 -> フラグに変換\n",
    "- 方向 -> 0/1に変換\n",
    "    - 上り: 0, 下り: 1\n",
    "- 四半期を数値化\n",
    "- 使用しないカラムを落とす\n",
    "    - 天気 + `index`, `data`, `road_code`, `jam_type`\n",
    "- 速度の欠損を埋める\n",
    "- OCC -> [0, 1]に変換\n",
    "- 型変換\n",
    "    - float64 -> float32\n",
    "    - 区間の名前, コード, 県コードをcategoryデータに\n",
    "    - degreeをint32\n",
    "    - 0/1系をint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3b58e808-e64e-4d7d-836d-04fd532a1054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_types = {'start_code': str, 'end_code': str, 'road_code': str, 'jam_type': str,}\n",
    "\n",
    "df = pd.read_csv(TRAFFIC_CSV, parse_dates=True, index_col='datetime', dtype=col_types).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "2898041e-0cc7-420f-9363-73a3edc61e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate(df, col):\n",
    "    '''\n",
    "    dfのcolカラム内の欠損を区間ごとに線形補間する\n",
    "    '''\n",
    "    f = lambda g: g.interpolate(method='linear', axis=0)\n",
    "    \n",
    "    df.sort_values('datetime', inplace=True)\n",
    "    df[col] = df.groupby(['start_code', 'end_code'])[col].apply(f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    # 「年」情報を入れる\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    # 渋滞フラグ 0/1\n",
    "    df['jam_quantity'] = np.where(df['speed'] < 40, 1, 0)\n",
    "    # 方向を数値化\n",
    "    direction_map = {'上り': 0, '下り': 1}\n",
    "    df['direction'] = df['direction'].map(direction_map)\n",
    "    # 四半期を数値化\n",
    "    df['quarter'] = df['quarter'].str[-1]\n",
    "    \n",
    "    # object型のカラム, いらないカラムを落とす\n",
    "    drop_cols = [\n",
    "        'index', 'date', 'road_code', 'pressure', 'rainfall', \n",
    "        'temperature', 'humidity', 'wind_speed', 'daylight_hours', \n",
    "        'snowfall', 'deepest_snowfall', 'weather_description', 'jam_type'\n",
    "    ]\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # 速度の欠損を埋める\n",
    "    df = linear_interpolate(df, 'speed')\n",
    "    # OCCを[0,1]に変換\n",
    "    df['OCC'] = df['OCC'] / 100.0\n",
    "    \n",
    "    # 型変換\n",
    "    f64_cols = df.select_dtypes(include=[np.float64]).columns\n",
    "    df.loc[:, f64_cols] = df.loc[:, f64_cols].astype(np.float32)\n",
    "    i64_cols = df.select_dtypes(include=[int]).columns\n",
    "    df.loc[:, i64_cols] = df.loc[:, i64_cols].astype(np.int32)\n",
    "    \n",
    "    type_map = {\n",
    "        'start_name': 'category',\n",
    "        'end_name': 'category',\n",
    "        'start_code': 'category',\n",
    "        'end_code': 'category',\n",
    "        'start_pref_code': 'category',\n",
    "        'end_pref_code': 'category',\n",
    "        'start_degree': np.int32,\n",
    "        'end_degree': np.int32,\n",
    "        'degree_sum': np.int32,\n",
    "        'direction': np.int32,\n",
    "        'quarter': np.int32,\n",
    "        'jam_quantity': np.int32,\n",
    "    }\n",
    "    df = df.astype(type_map)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23d5e8e-66a4-4c63-a76c-984f49cdec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, start_date, end_date, pkl_name):\n",
    "    tmp = df.loc[(df['datetime'] >= pd.Timestamp(start_date)) & (df['datetime'] < pd.Timestamp(end_date))]\n",
    "    # tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp = preprocess(tmp.copy())\n",
    "    tmp.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tmp.to_pickle(pkl_name)\n",
    "    \n",
    "\n",
    "# whole dataset\n",
    "# start_date = '2021/5/1'\n",
    "# end_date = '2022/6/1'\n",
    "# pkl_name = './datasets/kannetsu_210501-220601.pkl'\n",
    "\n",
    "# create_dataset(df, start_date, end_date, pkl_name)\n",
    "\n",
    "# mini dataset\n",
    "# start_date = '2021/5/1'\n",
    "# end_date = '2021/6/1'\n",
    "# pkl_name = './datasets/kannetsu_210501-210601.pkl'\n",
    "\n",
    "# create_dataset(df, start_date, end_date, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7f12-2979-4952-8165-d5c01122d1f9",
   "metadata": {},
   "source": [
    "## データセットを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2840688e-38f3-4355-bd7e-e1655e966cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini\n",
    "df_test = pd.read_pickle('./datasets/kannetsu_210501-210601.pkl')\n",
    "\n",
    "# whole\n",
    "# df_all = pd.read_pickle('./datasets/kannetsu_210501-220601.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a744fac3-59c4-423e-a2eb-00e283d6243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>start_name</th>\n",
       "      <th>end_name</th>\n",
       "      <th>start_code</th>\n",
       "      <th>end_code</th>\n",
       "      <th>start_pref_code</th>\n",
       "      <th>end_pref_code</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>search_unspec_3d</th>\n",
       "      <th>search_unspec_7d</th>\n",
       "      <th>search_unspec_10d</th>\n",
       "      <th>minute_quarter</th>\n",
       "      <th>allCars</th>\n",
       "      <th>jam_quantity</th>\n",
       "      <th>search_15min</th>\n",
       "      <th>OCC</th>\n",
       "      <th>speed</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>所沢</td>\n",
       "      <td>大泉ＪＣＴ</td>\n",
       "      <td>1800006</td>\n",
       "      <td>1110210</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>35.806149</td>\n",
       "      <td>35.755821</td>\n",
       "      <td>139.535507</td>\n",
       "      <td>...</td>\n",
       "      <td>6411.0</td>\n",
       "      <td>14134.0</td>\n",
       "      <td>18949.0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>91.289101</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>小出</td>\n",
       "      <td>大和ＰＡ</td>\n",
       "      <td>1800156</td>\n",
       "      <td>1800151</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.213329</td>\n",
       "      <td>37.160999</td>\n",
       "      <td>138.975403</td>\n",
       "      <td>...</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>5418.0</td>\n",
       "      <td>7059.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.869568</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>六日町</td>\n",
       "      <td>塩沢石打</td>\n",
       "      <td>1800146</td>\n",
       "      <td>1800141</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37.077942</td>\n",
       "      <td>36.990280</td>\n",
       "      <td>138.879288</td>\n",
       "      <td>...</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>5339.0</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.961540</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime start_name end_name start_code end_code start_pref_code  \\\n",
       "0 2021-05-01         所沢    大泉ＪＣＴ    1800006  1110210              11   \n",
       "1 2021-05-01         小出     大和ＰＡ    1800156  1800151              15   \n",
       "2 2021-05-01        六日町     塩沢石打    1800146  1800141              15   \n",
       "\n",
       "  end_pref_code  start_lat    end_lat   start_lng  ...  search_unspec_3d  \\\n",
       "0            13  35.806149  35.755821  139.535507  ...            6411.0   \n",
       "1            15  37.213329  37.160999  138.975403  ...            2446.0   \n",
       "2            15  37.077942  36.990280  138.879288  ...            2439.0   \n",
       "\n",
       "   search_unspec_7d  search_unspec_10d  minute_quarter  allCars  jam_quantity  \\\n",
       "0           14134.0            18949.0               0    211.0             0   \n",
       "1            5418.0             7059.0               0     23.0             0   \n",
       "2            5339.0             6888.0               0     26.0             0   \n",
       "\n",
       "   search_15min       OCC      speed  year  \n",
       "0           6.0  0.023333  91.289101  2021  \n",
       "1           1.0  0.000000  94.869568  2021  \n",
       "2           1.0  0.000000  91.961540  2021  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a0e9b-14b1-434c-8de6-2aa603db4727",
   "metadata": {},
   "source": [
    "## Spatial Temporal Matrixに整形\n",
    "- 区間数 x 時系列数 の行列\n",
    "- 実際は 区間数 x 時系列数 x 特徴量数 のテンソル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b39c58f-57dc-48c9-a557-0f5e71ead960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_col = ['datetime', 'start_name', 'end_name']\n",
    "\n",
    "# 特徴量の元になる列\n",
    "time_col = ['month', 'hour', 'dayofweek', 'is_holiday']\n",
    "section_col = ['direction', 'lane_count', 'KP']\n",
    "search_col = ['search_15min']\n",
    "traffic_col = ['allCars']\n",
    "\n",
    "feature_col = time_col + section_col + search_col + traffic_col\n",
    "\n",
    "# 予測対象\n",
    "target_col = 'allCars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59462320-290d-476a-908a-e39a226d8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_name</th>\n",
       "      <th>end_name</th>\n",
       "      <th>direction</th>\n",
       "      <th>KP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>長岡南越路スマート</td>\n",
       "      <td>小千谷</td>\n",
       "      <td>0</td>\n",
       "      <td>237.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>小千谷</td>\n",
       "      <td>越後川口</td>\n",
       "      <td>0</td>\n",
       "      <td>222.240005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>越後川口</td>\n",
       "      <td>堀之内</td>\n",
       "      <td>0</td>\n",
       "      <td>218.544998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_name end_name  direction          KP\n",
       "0  長岡南越路スマート      小千谷          0  237.699997\n",
       "1        小千谷     越後川口          0  222.240005\n",
       "2       越後川口      堀之内          0  218.544998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 区間情報を管理するためのテーブルを作成\n",
    "sec_table = df_test[['start_name', 'end_name', 'direction', 'KP']].drop_duplicates()\n",
    "# 区間順にソート\n",
    "sort_f = lambda g: g.sort_values('KP', ascending=(g.name == 1))\n",
    "sec_table = sec_table.groupby('direction').apply(sort_f).reset_index(drop=True)\n",
    "\n",
    "sec_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbce3814-436d-4547-a3fb-479f7fc14c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187488 63 2976\n",
      "torch.Size([63, 2976, 9]) torch.float32 torch.Size([63, 2976, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# データ数\n",
    "N = df_test.shape[0]\n",
    "# 区間数\n",
    "N_sec = sec_table.shape[0]\n",
    "# 時系列長\n",
    "N_period = N // N_sec\n",
    "print(N, N_sec, N_period)\n",
    "\n",
    "# 特徴量数\n",
    "D = len(feature_col)\n",
    "\n",
    "# 行列を準備\n",
    "X = torch.empty((N_sec, N_period, D), dtype=torch.float32)\n",
    "y = torch.empty((N_sec, N_period, 1), dtype=torch.float32)\n",
    "\n",
    "# 行列に区間ごとに値を入れていく\n",
    "for sec_id, (s_name, e_name, direction, _) in sec_table.iterrows():\n",
    "    query = f'start_name == \"{s_name}\" & end_name == \"{e_name}\" & direction == {direction}'\n",
    "    df_sec = df_test.query(query)\n",
    "    \n",
    "    data = df_sec.loc[:, feature_col]\n",
    "    target = df_sec.loc[:, target_col]\n",
    "    X[sec_id] = torch.from_numpy(data.values)\n",
    "    y[sec_id, :, 0] = torch.from_numpy(target.values)\n",
    "    \n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376cb0a-2709-4e34-94af-8c23af4a418f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 標準化・正規化\n",
    "- 標準化を行う\n",
    "- 時間特徴量（`month`, `hour`, `day_of_week`）はsin, cosで変換するのもやってみる\n",
    "- 検索数, 台数は上り・下り別でもやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5226b32-0321-439b-8af4-6cb334d969f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_encode(X):\n",
    "    eps = 1e-8\n",
    "    max_v, _ = X.view(-1, X.shape[-1]).max(dim=0)\n",
    "    X_cos = torch.cos(2 * torch.pi * X) / (max_v + eps)\n",
    "    X_sin = torch.sin(2 * torch.pi * X) / (max_v + eps)\n",
    "    return X_cos, X_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a520687-7ae5-4d6e-b369-7f5a4af42cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMatrixStandardScaler:\n",
    "    _direction_col = 4\n",
    "    _eps = 1e-8\n",
    "    \n",
    "    def __init__(self, by_up_down=False):\n",
    "        self.by_up_down = by_up_down\n",
    "    \n",
    "    def fit(self, X):\n",
    "        assert X.dim() == 3, 'X should be Spatial-Temporal Matrix (Sections x Periods x Features)'\n",
    "        S, T, D = X.shape\n",
    "        \n",
    "        if self.by_up_down:\n",
    "            X_up = X[X[..., self._direction_col] == 0].view(-1, T, D)\n",
    "            X_down = X[X[..., self._direction_col] == 1].view(-1, T, D)\n",
    "            \n",
    "            mean_up, std_up = self.__calc_params(X_up)\n",
    "            mean_down, std_down = self.__calc_params(X_down)\n",
    "            \n",
    "            self.mean_ = (mean_up, mean_down)\n",
    "            self.std_ = (std_up, std_down)\n",
    "        else:\n",
    "            mean, std = self.__calc_params(X)\n",
    "            self.mean_ = mean\n",
    "            self.std_ = std\n",
    "    \n",
    "    def transform(self, X):\n",
    "        S, T, D = X.shape\n",
    "        \n",
    "        if self.by_up_down:\n",
    "            X_up = X[X[..., self._direction_col] == 0].view(-1, T, D)\n",
    "            X_down = X[X[..., self._direction_col] == 1].view(-1, T, D)\n",
    "            \n",
    "            X_up_norm = self.__transform(X_up, self.mean_[0], self.std_[0])\n",
    "            X_down_norm = self.__transform(X_down, self.mean_[1], self.std_[1])\n",
    "            \n",
    "            X_norm = np.vstack((X_up_norm, X_down_norm))\n",
    "        else: \n",
    "            X_norm = self.__transform(X, self.mean_, self.std_)\n",
    "            \n",
    "        return X_norm\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        X_norm = self.transform(X)\n",
    "        return X_norm\n",
    "        \n",
    "    def inverse_transform(self, X):\n",
    "        X_origin = X * (self.std_ + self._eps) + self.mean_\n",
    "        return X_origin\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = {'mean': self.mean_, 'std': self.std_}\n",
    "        return params\n",
    "    \n",
    "    def __calc_params(self, X):\n",
    "        S, T, D = X.shape\n",
    "        mean = X.reshape(-1, D).mean(axis=0)\n",
    "        std = X.reshape(-1, D).std(axis=0)\n",
    "        return mean, std\n",
    "        \n",
    "    def __transform(self, X, mean, std):\n",
    "        X_norm = (X - mean) / (std + self._eps)\n",
    "        return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59f0469-e844-48d9-b897-4c4b2596f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = STMatrixStandardScaler()\n",
    "scaler.fit(X)\n",
    "X_norm = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a46d31-3c1c-494c-bc1f-6bfc8ec9b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_ratio):\n",
    "    assert X.dim() == 3, 'X should be Spatial-Temporal Matrix (Sections x Periods x Features)'\n",
    "    _, T, _ = X.shape\n",
    "    index_split = int(T * test_ratio)\n",
    "    X_train, X_test = X[:, :-index_split], X[:, -index_split:]\n",
    "    y_train, y_test = y[:, :-index_split], y[:, -index_split:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257b33a6-33cb-44fc-a345-50fb13db5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 2381, 9]) torch.Size([63, 2381, 1])\n",
      "torch.Size([63, 595, 9]) torch.Size([63, 595, 1])\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_norm, y, test_ratio)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae3bdf2-b682-49cf-bad4-efe91f223d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-B-C-D x 各区間10個ずつ\n",
    "# batch_size = 2\n",
    "# time_step = 3\n",
    "\n",
    "# AB0, AB1, AB2, ..., AB9\n",
    "# BC0, BC1, BC2, ..., BC9\n",
    "# CD0, CD1, CD2, ..., CD9\n",
    "\n",
    "# ABに限定するのであれば\n",
    "# [AB0, AB1, AB2], [AB1, AB2, AB3], ..., [AB7, AB8, AB9] -> 7個できる\n",
    "\n",
    "# バッチ数を区間数の倍数にすればいい？\n",
    "# [[AB0, AB1, AB2]\n",
    "# [BC0, BC1, BC2]\n",
    "# [CD0, CD1, CD2]]\n",
    "\n",
    "# 下みたいに区間に対応するラベルさえしっかり出力できるなら問題ない\n",
    "# [[AB0, AB1, AB2] -> AB3\n",
    "# [AB1, AB2, AB3] -> AB4\n",
    "# [AB5, AB6, AB7] -> AB8\n",
    "# [BC2, BC3, BC4] -> BC5\n",
    "# [BC7, BC8, BC9] -> BC10\n",
    "# [CD0, CD1, CD2]] -> CD3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b4d27-83ee-4e74-8cbd-e2f88b5bc7e3",
   "metadata": {},
   "source": [
    "## データセットの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ac3617-b1b0-4048-bda2-6a1cb22cb28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "# 必要なもの: X, y, time_window, space_window, prediction_horizon\n",
    "\n",
    "class STDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, time_step, prediction_horizon=1, space_window=None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X:\n",
    "        y:\n",
    "        time_step: int\n",
    "            過去を参照する時間幅 (x 15min)\n",
    "        prediction_horizon: int\n",
    "            いくつ先のstepを予測するか (>= 1 x 15min)\n",
    "        space_window: Tuple\n",
    "            前後の区間をいくつ参照するか\n",
    "        '''\n",
    "        assert X.dim() == 3, 'X should be Spatial-Temporal Matrix (Sections x Periods x Features)'\n",
    "        assert y.dim() == 3, 'y should be Spatial-Temporal Matrix (Sections x Periods x 1 (label))'\n",
    "        \n",
    "        assert time_step > 0, 'time step must be >0 (x15min)'\n",
    "        assert prediction_horizon > 0, 'prediction horizon must be >0 (x15min)'\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.space_window = space_window\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        \n",
    "        if space_window is not None:\n",
    "            assert isinstance(space_window, (list, tuple)), 'space window must be List[int] or Tuple[int]'\n",
    "            assert isinstance(space_window[0], int), 'space window must be List[int] or Tuple[int]'\n",
    "            assert len(space_window) == 2, 'space window must be (-upstream_step, downstream_step)'\n",
    "            f, l = self.__sliding_space(X, y)\n",
    "            features, labels = self.__sliding_window(f, l)\n",
    "        else:\n",
    "            features, labels = self.__sliding_window(X, y)\n",
    "            \n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "    \n",
    "    def __sliding_space(self, X, y):\n",
    "        S, T, D = X.shape\n",
    "        s_window = self.space_window\n",
    "        s_len = s_window[1] - s_window[0] + 1\n",
    "        \n",
    "        features = torch.empty((S, T, D, s_len), dtype=torch.float32)\n",
    "        labels = torch.empty((S, T, 1, s_len), dtype=torch.float32)\n",
    "        \n",
    "        for i in range(S):\n",
    "            # 各区間の前後区間を切り出す\n",
    "            for offset in range(s_window[0], s_window[1]+1):\n",
    "                j = i + offset\n",
    "                # paddingする\n",
    "                if j < 0:\n",
    "                    j = 0\n",
    "                elif j >= S:\n",
    "                    j = S-1\n",
    "\n",
    "                features[i, ..., offset] = X[j]\n",
    "                labels[i, ..., offset] = y[j]\n",
    "        \n",
    "        return features, labels\n",
    "        \n",
    "    \n",
    "    def __sliding_window(self, X, y):\n",
    "        S, T, *_ = X.shape\n",
    "        t_step = self.time_step\n",
    "        p_horizon = self.prediction_horizon\n",
    "        \n",
    "        features = []\n",
    "        labels = []\n",
    "        for i in range(S):\n",
    "            # 各区間ごとに過去time step分だけ切り出す\n",
    "            for t in range(t_step, T - p_horizon + 1):\n",
    "                feature = X[i, t-t_step:t+p_horizon-1]\n",
    "                label = y[i, t+p_horizon-1]\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "\n",
    "        features = torch.cat(features, dim=0).view(len(features), *features[0].shape)\n",
    "        labels = torch.cat(labels, dim=0).view(len(labels), *labels[0].shape)\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6731a3ac-b9fc-46dd-87d4-050fa49aee96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_step = 96\n",
    "prediction_horizon = 1\n",
    "space_window = None\n",
    "\n",
    "dataset_train = STDataset(X_train, y_train, time_step=time_step, prediction_horizon=prediction_horizon)\n",
    "dataset_valid = STDataset(X_val, y_val, time_step=time_step, prediction_horizon=prediction_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340b55f-dcc6-4f86-a1d9-ed3c02faaaf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a17bfe-5110-4967-9810-f2b11c7bddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, num_layers, batch_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_dim, hid_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outs, (h, c) = self.lstm(x)\n",
    "        out = self.fc(h[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41aa92-6edb-4ee7-940c-990101e90046",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab3e372-219a-45e6-807f-802404cf8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c322e5d-ec12-4ce1-be2c-c78628467dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 150\n",
    "in_dim = X_train.shape[-1]\n",
    "hid_dim = 32\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "017d5633-9119-4d18-b805-7f3a0f64c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()\n",
    "trainer = Trainer(model, optimizer, loss_fn, device=device, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed214934-0aab-4ae0-8701-4f692c8f670f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-06 03:20:09.021559 | Epoch: 1 | Train Loss: 200.575, Train Time: 2.74 [sec] | Valid Loss: 184.510, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:20:12.083290 | Epoch: 2 | Train Loss: 183.791, Train Time: 2.61 [sec] | Valid Loss: 170.499, Valid Time: 0.45 [sec]\n",
      "2022-08-06 03:20:15.141265 | Epoch: 3 | Train Loss: 172.137, Train Time: 2.74 [sec] | Valid Loss: 161.208, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:20:18.328505 | Epoch: 4 | Train Loss: 162.574, Train Time: 2.87 [sec] | Valid Loss: 149.412, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:20:21.269778 | Epoch: 5 | Train Loss: 150.111, Train Time: 2.62 [sec] | Valid Loss: 138.959, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:21:06.938881 | Epoch: 20 | Train Loss: 60.646, Train Time: 2.66 [sec] | Valid Loss: 54.852, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:22:08.107499 | Epoch: 40 | Train Loss: 23.828, Train Time: 2.75 [sec] | Valid Loss: 21.290, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:23:09.465650 | Epoch: 60 | Train Loss: 16.421, Train Time: 2.80 [sec] | Valid Loss: 15.701, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:24:09.685023 | Epoch: 80 | Train Loss: 14.957, Train Time: 2.79 [sec] | Valid Loss: 14.602, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:25:10.178142 | Epoch: 100 | Train Loss: 14.431, Train Time: 2.71 [sec] | Valid Loss: 14.405, Valid Time: 0.32 [sec]\n",
      "2022-08-06 03:26:10.239621 | Epoch: 120 | Train Loss: 14.139, Train Time: 2.56 [sec] | Valid Loss: 14.134, Valid Time: 0.45 [sec]\n",
      "2022-08-06 03:27:10.450765 | Epoch: 140 | Train Loss: 13.949, Train Time: 2.69 [sec] | Valid Loss: 14.075, Valid Time: 0.32 [sec]\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = \\\n",
    "    trainer.fit(train_loader, val_loader, n_epochs, log_steps=20, max_first_log_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95806d53-47b4-4009-b34f-c4706e0fb947",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 学習曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afb674a8-cb27-4040-ae77-1b140045fe1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(range(len(train_losses)), train_losses)\n",
    "ax.plot(range(len(val_losses)), val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "313512b5-4c4d-48aa-ba0f-63c3d3e74035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.723643863603446\n",
      "14.061335032548362\n"
     ]
    }
   ],
   "source": [
    "print(trainer.validate(train_loader))\n",
    "print(trainer.validate(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cf31515-ea07-48d8-bcdb-c7f4a13762e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_table.to_pickle('section_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "70220b82-63db-44ff-94e5-670621ccdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = df_test[(df_test['start_name'] == '鶴ヶ島') & (df_test['direction'] == 1)]\n",
    "tmp_train = tmp_train.loc[:, key_col + features]\n",
    "\n",
    "# 時系列長\n",
    "N_period = tmp_train.drop_duplicates(\"datetime\").shape[0]\n",
    "# 区間数\n",
    "N_sec = tmp_train.drop_duplicates([\"start_name\", \"end_name\"]).shape[0]\n",
    "# 特徴量数\n",
    "D = len(features)\n",
    "\n",
    "tmp_train_value = tmp_train[features].values.reshape(1, N_period, D)\n",
    "tmp_train_norm = (tmp_train_value - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2c6c00c2-90d7-4da0-963f-7f631e0a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X = []\n",
    "\n",
    "for i in range(N_sec):\n",
    "    for t in range(time_step, N_period - 24):\n",
    "        time_pred = t + 24\n",
    "        time_input = (t - time_step, t + time_step + 1)\n",
    "        x_ = tmp_train_norm[i, time_input[0] : time_input[1]]\n",
    "        tmp_X.append(x_)\n",
    "\n",
    "tmp_X = torch.from_numpy(np.array(tmp_X, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f1369b62-c2ce-4512-a50c-e050ade2ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model(tmp_X.to(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "741a600e-c0c8-4e35-ab44-0070998eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.arange(time_step, N_period - 24) + 24\n",
    "tmp_y = tmp_train.iloc[ys, -1].values.reshape(-1, 1)\n",
    "tmp_y = torch.from_numpy(tmp_y).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "75c7908b-8ca8-45f2-ab77-9f9571a38319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2830.],\n",
       "        [2699.],\n",
       "        [2518.],\n",
       "        [2320.],\n",
       "        [2056.],\n",
       "        [1892.],\n",
       "        [1657.],\n",
       "        [1534.],\n",
       "        [1343.],\n",
       "        [ 890.]], device='cuda:0')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bfc7632f-df57-4347-a9e6-bf336e0cfdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1906.3523],\n",
       "        [2111.0740],\n",
       "        [1478.2659],\n",
       "        [1709.9409],\n",
       "        [1561.3125],\n",
       "        [1184.2350],\n",
       "        [1547.8439],\n",
       "        [1354.0841],\n",
       "        [ 719.4714],\n",
       "        [ 688.2144]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1f122439-cf23-4510-9a91-ab1dfab22159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1 -------\n",
      "tensor(126.)\n",
      "tensor([115.0645], device='cuda:0')\n",
      "10.935508728027344\n",
      "\n",
      "------- 2 -------\n",
      "tensor(134.)\n",
      "tensor([134.9498], device='cuda:0')\n",
      "0.9497833251953125\n",
      "\n",
      "------- 3 -------\n",
      "tensor(170.)\n",
      "tensor([168.9665], device='cuda:0')\n",
      "1.0334625244140625\n",
      "\n",
      "------- 4 -------\n",
      "tensor(198.)\n",
      "tensor([204.4083], device='cuda:0')\n",
      "6.4083099365234375\n",
      "\n",
      "------- 5 -------\n",
      "tensor(179.)\n",
      "tensor([184.3132], device='cuda:0')\n",
      "5.313201904296875\n",
      "\n",
      "------- 6 -------\n",
      "tensor(202.)\n",
      "tensor([209.7910], device='cuda:0')\n",
      "7.79095458984375\n",
      "\n",
      "------- 7 -------\n",
      "tensor(224.)\n",
      "tensor([240.2662], device='cuda:0')\n",
      "16.266204833984375\n",
      "\n",
      "------- 8 -------\n",
      "tensor(317.)\n",
      "tensor([303.8457], device='cuda:0')\n",
      "13.154327392578125\n",
      "\n",
      "------- 9 -------\n",
      "tensor(383.)\n",
      "tensor([374.0816], device='cuda:0')\n",
      "8.918426513671875\n",
      "\n",
      "------- 10 -------\n",
      "tensor(440.)\n",
      "tensor([439.5305], device='cuda:0')\n",
      "0.469482421875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65/1850680170.py:11: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for data, target in dataset_train:\n",
    "        if i >= 10:\n",
    "            break\n",
    "        i += 1\n",
    "        print(f'------- {i} -------')\n",
    "        out = model(data.to(device=device))\n",
    "        print(target)\n",
    "        print(out)\n",
    "        print(torch.sqrt(nn.functional.mse_loss(out, target.to(device=device))).item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "105cdb92-cd84-4abb-97f8-65ea5a5f3cf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:24:34.155558 | Epoch 1 | Loss: 65953.34375\n",
      "2022-07-21 17:24:40.475783 | Epoch 2 | Loss: 6871.1943359375\n",
      "2022-07-21 17:24:46.874386 | Epoch 3 | Loss: 11021.1640625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [339]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     15\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     17\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     18\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 3000\n",
    "in_dim = X_train.shape[-1]\n",
    "hid_dim = 100\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = Net(in_dim, hid_dim, out_dim, num_layers).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device=device)\n",
    "        target = target.unsqueeze(1).to(device=device)\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses.append(total_loss)\n",
    "\n",
    "    if epoch < 3 or (epoch + 1) % 100 == 0:\n",
    "        print(f'{dt.datetime.now()} | Epoch {epoch+1} | Loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
